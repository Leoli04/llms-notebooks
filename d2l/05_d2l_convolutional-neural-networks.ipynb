{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b76a76e6-9d95-4344-b2ae-7ed2ff5a2a0a",
   "metadata": {},
   "source": [
    "# 卷积神经网络\n",
    "本章介绍的卷积神经网络（convolutional neural network，CNN）是一类强大的、为处理图像数据而设计的神经网络。 基于卷积神经网络架构的模型在计算机视觉领域中已经占主导地位，当今几乎所有的图像识别、目标检测或语义分割相关的学术竞赛和商业应用都以这种方法为基础。\n",
    "\n",
    "在本章的开始，我们将介绍构成所有卷积网络主干的基本元素。 这包括卷积层本身、填充（padding）和步幅（stride）的基本细节、用于在相邻区域汇聚信息的汇聚层（pooling）、在每一层中多通道（channel）的使用，以及有关现代卷积网络架构的仔细讨论。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64077bc-0829-440b-b7b8-dfc2650bc5c2",
   "metadata": {},
   "source": [
    "## 从全连接层到卷积\n",
    "\n",
    "我们之前讨论的多层感知机十分适合处理表格数据，其中行对应样本，列对应特征。 对于表格数据，我们寻找的模式可能涉及特征之间的交互，但是我们不能预先假设任何与特征交互相关的先验结构。 此时，多层感知机可能是最好的选择，然而对于高维感知数据，这种缺少结构的网络可能会变得不实用。\n",
    "\n",
    "卷积神经网络（convolutional neural networks，CNN）是机器学习利用自然图像中一些已知结构的创造性方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cf0071-fd89-426e-8782-cb43aa692785",
   "metadata": {},
   "source": [
    "### 不变性\n",
    "1. *平移不变性*（translation invariance）：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。\n",
    "1. *局部性*（locality）：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e1a498-640a-47bd-b36d-a7fb4419458d",
   "metadata": {},
   "source": [
    "### 多层感知机的限制\n",
    "利用不变性，使用全连接演变到卷积：\n",
    "\n",
    "使用$[\\mathbf{X}]_{i, j}$和$[\\mathbf{H}]_{i, j}$分别表示输入图像和隐藏表示中位置（$i$,$j$）处的像素。\n",
    "为了使每个隐藏神经元都能接收到每个输入像素的信息，我们将参数从权重矩阵（如同我们先前在多层感知机中所做的那样）替换为四阶权重张量$\\mathsf{W}$。假设$\\mathbf{U}$包含偏置参数，我们可以将全连接层形式化地表示为\n",
    "\n",
    "$$\\begin{aligned} \\left[\\mathbf{H}\\right]_{i, j} &= [\\mathbf{U}]_{i, j} + \\sum_k \\sum_l[\\mathsf{W}]_{i, j, k, l}  [\\mathbf{X}]_{k, l}\\\\ &=  [\\mathbf{U}]_{i, j} +\n",
    "\\sum_a \\sum_b [\\mathsf{V}]_{i, j, a, b}  [\\mathbf{X}]_{i+a, j+b}.\\end{aligned}$$\n",
    "\n",
    "其中，从$\\mathsf{W}$到$\\mathsf{V}$的转换只是形式上的转换，因为在这两个四阶张量的元素之间存在一一对应的关系。\n",
    "\n",
    "#### 平移不变性\n",
    "图像的平移不变性使我们以相同的方式处理局部图像，而不在乎它的位置。也就是说，$\\mathsf{V}$和$\\mathbf{U}$实际上不依赖于$(i, j)$的值，即$[\\mathsf{V}]_{i, j, a, b} = [\\mathbf{V}]_{a, b}$。并且$\\mathbf{U}$是一个常数，比如$u$。因此，我们可以简化$\\mathbf{H}$定义为：\n",
    "\n",
    "$$[\\mathbf{H}]_{i, j} = u + \\sum_a\\sum_b [\\mathbf{V}]_{a, b} [\\mathbf{X}]_{i+a, j+b}.$$\n",
    "\n",
    "这就是*卷积*（convolution）。我们是在使用系数$[\\mathbf{V}]_{a, b}$对位置$(i, j)$附近的像素$(i+a, j+b)$进行加权得到$[\\mathbf{H}]_{i, j}$。\n",
    "\n",
    "#### 局部性\n",
    "局部性意味着计算相应的隐藏表示只需一小部分局部图像像素。如上所述，为了收集用来训练参数$[\\mathbf{H}]_{i, j}$的相关信息，我们不应偏离到距$(i, j)$很远的地方。这意味着在$|a|> \\Delta$或$|b| > \\Delta$的范围之外，我们可以设置$[\\mathbf{V}]_{a, b} = 0$。因此，我们可以将$[\\mathbf{H}]_{i, j}$重写为\n",
    "\n",
    "$$[\\mathbf{H}]_{i, j} = u + \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} [\\mathbf{V}]_{a, b}  [\\mathbf{X}]_{i+a, j+b}.$$\n",
    "\n",
    "\n",
    "简而言之， 上述是一个*卷积层*（convolutional layer），而卷积神经网络是包含卷积层的一类特殊的神经网络。\n",
    "在深度学习研究社区中，$\\mathbf{V}$被称为*卷积核*（convolution kernel）或者*滤波器*（filter），亦或简单地称之为该卷积层的*权重*，通常该权重是可学习的参数。\n",
    "\n",
    " 当图像处理的局部区域很小时，卷积神经网络与多层感知机的训练差异可能是巨大的：以前，多层感知机可能需要数十亿个参数来表示网络中的一层，而现在卷积神经网络通常只需要几百个参数，而且不需要改变输入或隐藏表示的维数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548edcd-a058-43a2-861f-5c1d380bdb13",
   "metadata": {},
   "source": [
    "### 卷积\n",
    "卷积是一种将两个函数结合生成第三个函数的运算，描述了一个函数如何通过另一个函数的翻转和滑动来变化。\n",
    "在数学中，两个函数（比如$f, g: \\mathbb{R}^d \\to \\mathbb{R}$）之间的“卷积”被定义为\n",
    "\n",
    "$$(f * g)(\\mathbf{x}) = \\int f(\\mathbf{z}) g(\\mathbf{x}-\\mathbf{z}) d\\mathbf{z}.$$\n",
    "\n",
    "也就是说，卷积是当把一个函数“翻转”并移位$\\mathbf{x}$时，测量$f$和$g$之间的重叠。\n",
    "当为离散对象时，积分就变成求和。例如，对于由索引为$\\mathbb{Z}$的、平方可和的、无限维向量集合中抽取的向量，我们得到以下定义：\n",
    "\n",
    "$$(f * g)(i) = \\sum_a f(a) g(i-a).$$\n",
    "\n",
    "对于二维张量，则为$f$的索引$(a, b)$和$g$的索引$(i-a, j-b)$上的对应加和：\n",
    "\n",
    "$$(f * g)(i, j) = \\sum_a\\sum_b f(a, b) g(i-a, j-b).$$\n",
    ":eqlabel:`eq_2d-conv-discrete`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121896ff-6bf1-40d2-af1f-2d4fbd7dd178",
   "metadata": {},
   "source": [
    "### 小结\n",
    "- 对全连接层使用平移不变性和局部性得到卷积层。\n",
    "- 在图像处理中，卷积层通常比全连接层需要更少的参数，但依旧获得高效用的模型。\n",
    "- 卷积神经网络（CNN）是一类特殊的神经网络，它可以包含多个卷积层。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96edd9f8-9b33-4b4c-aeb1-01ff7711b886",
   "metadata": {},
   "source": [
    "## 图像卷积\n",
    "卷积神经网络的设计是用于探索图像数据，本节我们将以图像为例。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4375ca-f8e9-4ded-b4db-7e450140019d",
   "metadata": {},
   "source": [
    "### 互相关运算\n",
    "\n",
    "严格来说，卷积层是个错误的叫法，因为它所表达的运算其实是互相关运算（cross-correlation），而不是卷积运算。 根据 6.1节中的描述，在卷积层中，输入张量和核张量通过互相关运算产生输出张量。\n",
    "\n",
    "首先，我们暂时忽略通道（第三维）这一情况，看看如何处理二维图像数据和隐藏表示。在 下图中，输入是高度为$3$、宽度为$3$的二维张量（即形状为$3 \\times 3$）。卷积核的高度和宽度都是$2$，而卷积核窗口（或卷积窗口）的形状由内核的高度和宽度决定（即$2 \\times 2$）。\n",
    "\n",
    "![二维互相关运算。阴影部分是第一个输出元素，以及用于计算输出的输入张量元素和核张量元素：$0\\times0+1\\times1+3\\times2+4\\times3=19$.](http://d2l.ai/_images/correlation.svg)\n",
    "\n",
    "\n",
    "在二维互相关运算中，卷积窗口从输入张量的左上角开始，从左到右、从上到下滑动。\n",
    "当卷积窗口滑动到新一个位置时，包含在该窗口中的部分张量与卷积核张量进行按元素相乘，得到的张量再求和得到一个单一的标量值，由此我们得出了这一位置的输出张量值。\n",
    "在如上例子中，输出张量的四个元素由二维互相关运算得到，这个输出高度为$2$、宽度为$2$，如下所示：\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae33e8b-5f21-42c3-8576-f11264c32ce1",
   "metadata": {},
   "source": [
    "$$0\\times0+1\\times1+3\\times2+4\\times3=19,$$\n",
    "$$1\\times0+2\\times1+4\\times2+5\\times3=25,$$\n",
    "$$3\\times0+4\\times1+6\\times2+7\\times3=37,$$\n",
    "$$4\\times0+5\\times1+7\\times2+8\\times3=43.$$\n",
    "\n",
    "输出大小等于输入大小$n_h \\times n_w$减去卷积核大小$k_h \\times k_w$，即：\n",
    "\n",
    "$$(n_h-k_h+1) \\times (n_w-k_w+1).$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f22da4e-a322-40d7-9d22-3776e5682521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们在corr2d函数中实现如上过程，该函数接受输入张量X和卷积核张量K，并返回输出张量Y。\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def corr2d(X, K):  #@save\n",
    "    \"\"\"计算二维互相关运算\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a769676-dc7c-40e0-a91e-c867d51876bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a110e6e-6460-4308-8e3a-59cbfbddc781",
   "metadata": {},
   "source": [
    "### 卷积层\n",
    "卷积层对输入和卷积核权重进行互相关运算，并在添加标量偏置之后产生输出。 所以，卷积层中的两个被训练的参数是卷积核权重和标量偏置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d895309-d7f7-4dc3-8820-02c613b57a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    # weight和bias声明为两个模型参数\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    # 前向传播函数调用corr2d函数并添加偏置。\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3bc501-b255-4079-a8f2-37105f538246",
   "metadata": {},
   "source": [
    "高度和宽度分别为$h$和$w$的卷积核可以被称为$h \\times w$卷积或$h \\times w$卷积核。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d20d6b-f2af-49b7-b863-eeff152be08b",
   "metadata": {},
   "source": [
    "### 图像中目标的边缘检测\n",
    "\n",
    "如下是[**卷积层的一个简单应用：**]通过找到像素变化的位置，来(**检测图像中不同颜色的边缘**)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc2ee35d-7fd3-437f-9639-db035117e4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造一个$6\\times 8$像素的黑白图像。中间四列为黑色（$0$），其余像素为白色（$1$）。\n",
    "X = torch.ones((6, 8))\n",
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3069f165-9067-4e32-b99a-bbaa648211f5",
   "metadata": {},
   "source": [
    "#构造一个高度为$1$、宽度为$2$的卷积核`K`。当进行互相关运算时，如果水平相邻的两元素相同，则输出为零，否则输出为非零。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4819a0c-7b73-4f78-b8e7-23f2951131eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "K = torch.tensor([[1.0, -1.0]])\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98dbc80-66cb-428b-8137-d5a72bb4e359",
   "metadata": {},
   "source": [
    "输出`Y`中的1代表从白色到黑色的边缘，-1代表从黑色到白色的边缘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f2f2968-ec0a-4f5c-9881-11855f27cf5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Y = corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75b58293-71ea-451f-a064-18b2b09bc762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X.t(), K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff94351-e3e6-4c87-8a1c-107b0456b054",
   "metadata": {},
   "source": [
    "### 学习卷积核\n",
    "\n",
    "上面是通过自己定义的卷积核，我们也可以通过仅查看“输入-输出”对来学习由X生成Y的卷积核。\n",
    "\n",
    "我们先构造一个卷积层，并将其卷积核初始化为随机张量。接下来，在每次迭代中，我们比较Y与卷积层输出的平方误差，然后计算梯度来更新卷积核。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a0b55a-e593-41be-acc6-ade495dc88b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d.weight.data: tensor([[[[-0.4883, -0.4685]]]])\n",
      "conv2d.weight.grad: tensor([[[[-40.8210, -16.5831]]]])\n",
      "conv2d.weight.data: tensor([[[[0.7363, 0.0290]]]])\n",
      "conv2d.weight.grad: tensor([[[[15.2055, 30.7178]]]])\n",
      "epoch 2, loss 13.800\n",
      "conv2d.weight.data: tensor([[[[ 0.2802, -0.8925]]]])\n",
      "conv2d.weight.grad: tensor([[[[-23.3332, -13.4054]]]])\n",
      "conv2d.weight.data: tensor([[[[ 0.9802, -0.4903]]]])\n",
      "conv2d.weight.grad: tensor([[[[11.5185, 17.8724]]]])\n",
      "epoch 4, loss 4.440\n",
      "conv2d.weight.data: tensor([[[[ 0.6346, -1.0265]]]])\n",
      "conv2d.weight.grad: tensor([[[[-13.7896,  -9.7231]]]])\n",
      "conv2d.weight.data: tensor([[[[ 1.0483, -0.7348]]]])\n",
      "conv2d.weight.grad: tensor([[[[ 8.1038, 10.7063]]]])\n",
      "epoch 6, loss 1.615\n",
      "conv2d.weight.data: tensor([[[[ 0.8052, -1.0560]]]])\n",
      "conv2d.weight.grad: tensor([[[[-8.3569, -6.6912]]]])\n",
      "conv2d.weight.data: tensor([[[[ 1.0559, -0.8553]]]])\n",
      "conv2d.weight.grad: tensor([[[[5.4863, 6.5522]]]])\n",
      "epoch 8, loss 0.628\n",
      "conv2d.weight.data: tensor([[[[ 0.8913, -1.0518]]]])\n",
      "conv2d.weight.grad: tensor([[[[-5.1565, -4.4743]]]])\n",
      "conv2d.weight.data: tensor([[[[ 1.0460, -0.9176]]]])\n",
      "conv2d.weight.grad: tensor([[[[3.6340, 4.0706]]]])\n",
      "epoch 10, loss 0.251\n"
     ]
    }
   ],
   "source": [
    "# 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核\n",
    "conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)\n",
    "\n",
    "# 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），\n",
    "# 其中批量大小和通道数都为1\n",
    "X = X.reshape((1, 1, 6, 8))\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "lr = 3e-2  # 学习率\n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = (Y_hat - Y) ** 2\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    # print(\"conv2d.weight.data:\",conv2d.weight.data)\n",
    "    # print(\"conv2d.weight.grad:\",conv2d.weight.grad)\n",
    "    # 迭代卷积核\n",
    "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f'epoch {i+1}, loss {l.sum():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa12c822-79e3-4cf4-b549-409a4ade4103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9370, -1.0397]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data.reshape((1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3221f53-c52a-455e-b548-4c3df6e70fd8",
   "metadata": {},
   "source": [
    "上面和我们上面自己定义的非常接近"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1b090c-94c7-4730-b526-3a59b5f42150",
   "metadata": {},
   "source": [
    "### 互相关和卷积\n",
    "\n",
    "互相关和卷积运算，它们差别不大，我们只需水平和垂直翻转二维卷积核张量，然后对输入张量执行互相关运算。由于卷积核是从数据中学习到的，因此无论这些层执行严格的卷积运算还是互相关运算，卷积层的输出都不会受到影响。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d8600e-bab9-473d-b22a-ef7df6411095",
   "metadata": {},
   "source": [
    "### 特征映射和感受野\n",
    "\n",
    "在互相关运算中，输出的卷积层有时被称为特征映射（feature map），因为它可以被视为一个输入映射到下一层的空间维度的转换器。\n",
    "\n",
    "在卷积神经网络中，对于某一层的任意元素$x$，其*感受野*（receptive field）是指在前向传播期间可能影响$x$计算的所有元素（来自所有先前层）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fe9930-cf65-4ae7-af68-a6c3d7b0f7ad",
   "metadata": {},
   "source": [
    "### 小结\n",
    "* 二维卷积层的核心计算是二维互相关运算。最简单的形式是，对二维输入数据和卷积核执行互相关操作，然后添加一个偏置。\n",
    "* 我们可以设计一个卷积核来检测图像的边缘。\n",
    "* 我们可以从数据中学习卷积核的参数。\n",
    "* 学习卷积核时，无论用严格卷积运算或互相关运算，卷积层的输出不会受太大影响。\n",
    "* 当需要检测输入特征中更广区域时，我们可以构建一个更深的卷积网络。\n",
    "* 核矩阵的大小是超参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fdfe14-89a6-4f62-9d80-55055d8acb82",
   "metadata": {},
   "source": [
    "## 填充和步幅\n",
    "\n",
    "在前面章节介绍过，假设输入形状为$n_h\\times n_w$，卷积核形状为$k_h\\times k_w$，那么输出形状将是$(n_h-k_h+1) \\times (n_w-k_w+1)$。\n",
    "因此，卷积的输出形状取决于输入形状和卷积核的形状。\n",
    "\n",
    "还有什么因素会影响输出的大小呢？本节我们将介绍*填充*（padding）和*步幅*（stride）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c82b55-35e2-4757-82f6-2d1f47b57006",
   "metadata": {},
   "source": [
    "### 填充\n",
    "填充（padding）是指在输入数据的边界周围添加额外的元素，通常这些元素的值为0。这样做主要是为了：\n",
    "- 保持边缘信息：随着我们应用许多连续卷积层，累积丢失的像素数就多了\n",
    "- 控制输出尺寸：通过适当的填充，可以控制卷积操作后的输出尺寸，使其与输入尺寸相同或符合预期的大小。\n",
    "\n",
    "通常，如果我们添加$p_h$行填充（大约一半在顶部，一半在底部）和$p_w$列填充（左侧大约一半，右侧一半），则输出形状将为\n",
    "\n",
    "$$(n_h-k_h+p_h+1)\\times(n_w-k_w+p_w+1)。$$\n",
    "\n",
    "这意味着输出的高度和宽度将分别增加$p_h$和$p_w$。在许多情况下，我们需要设置$p_h=k_h-1$和$p_w=k_w-1$，使输入和输出具有相同的高度和宽度。\n",
    "\n",
    "假设$k_h$是奇数，我们将在高度的两侧填充$p_h/2$行。\n",
    "如果$k_h$是偶数，则一种可能性是在输入顶部填充$\\lceil p_h/2\\rceil$行，在底部填充$\\lfloor p_h/2\\rfloor$行。同理，我们填充宽度的两侧。\n",
    "\n",
    "卷积神经网络中卷积核的高度和宽度通常为奇数，例如1、3、5或7。选择奇数的好处是，保持空间维度的同时，我们可以在顶部和底部填充相同数量的行，在左侧和右侧填充相同数量的列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b78d6759-a6b6-4741-9510-a0bc9f603a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# 为了方便起见，我们定义了一个计算卷积层的函数。\n",
    "# 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # 这里的（1，1）表示批量大小和通道数都是1\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # 省略前两个维度：批量大小和通道\n",
    "    return Y.reshape(Y.shape[2:])\n",
    "\n",
    "# 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)\n",
    "X = torch.rand(size=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0ee36c-b365-4ddf-acfa-046a32a47cfa",
   "metadata": {},
   "source": [
    "当卷积核的高度和宽度不同时，我们可以填充不同的高度和宽度，使输出和输入具有相同的高度和宽度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea11ce61-549c-4e12-9ff8-b09924fda228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5365028-6517-43d5-8c6d-13bc20d6107a",
   "metadata": {},
   "source": [
    "### 步幅\n",
    "步幅（stride)是卷积核在输入数据上移动时的间隔或步长。它决定了卷积核每次移动的距离。\n",
    "\n",
    "作用：\n",
    "- 减少计算量：通过设置较大的步幅，可以减少卷积核在输入数据上的采样点，从而降低计算复杂度。\n",
    "- 降采样：步幅大于1时，可以实现降采样效果，即减小输出数据的尺寸。这有助于提取更高级别的特征并减少数据的维度。\n",
    "\n",
    "通常，当垂直步幅为$s_h$、水平步幅为$s_w$时，输出形状为\n",
    "\n",
    "$$\\lfloor(n_h-k_h+p_h+s_h)/s_h\\rfloor \\times \\lfloor(n_w-k_w+p_w+s_w)/s_w\\rfloor.$$\n",
    "\n",
    "如果我们设置了$p_h=k_h-1$和$p_w=k_w-1$，则输出形状将简化为$\\lfloor(n_h+s_h-1)/s_h\\rfloor \\times \\lfloor(n_w+s_w-1)/s_w\\rfloor$。\n",
    "更进一步，如果输入的高度和宽度可以被垂直和水平步幅整除，则输出形状将为$(n_h/s_h) \\times (n_w/s_w)$。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60ef32d3-bbab-4fbb-be4c-313cdce179a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将高度和宽度的步幅设置为2，从而将输入的高度和宽度减半。\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cf42613-6910-4375-86a2-174906456457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a056a89a-b9aa-40c0-8783-fe2cb90e5675",
   "metadata": {},
   "source": [
    "默认情况下，填充为0，步幅为1。在"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce86657e-8e8e-430f-94c7-f35dc49cee21",
   "metadata": {},
   "source": [
    "### 小结\n",
    "- 填充和步幅是卷积层的超参数\n",
    "- 填充在输入周围添加额外的行/列，来控制输出形状的减少量\n",
    "- 步幅是每次滑动核窗口时的行/列的步长，可以成倍的减少输出形状"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8367ab9-5997-4794-831e-6356d2d4bb97",
   "metadata": {},
   "source": [
    "## 多输入多输出通道\n",
    "\n",
    "彩色图像具有标准的RGB通道来代表红、绿和蓝。 每个RGB输入图像具有$3\\times h\\times w$的形状。我们将这个大小为$3$的轴称为*通道*（channel）维度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ccf5a3-5ebd-4681-ad63-28bdea48413c",
   "metadata": {},
   "source": [
    "### 多输入通道\n",
    "\n",
    "**每个通道都有一个卷积核，结果是所有通道卷积结果的和。**\n",
    "\n",
    "在下图中，我们演示了一个具有两个输入通道的二维互相关运算的示例。阴影部分是第一个输出元素以及用于计算这个输出的输入和核张量元素：$(1\\times1+2\\times2+4\\times3+5\\times4)+(0\\times0+1\\times1+3\\times2+4\\times3)=56$。\n",
    "\n",
    "![两个输入通道的互相关计算。](../image/conv-multi-in.svg)\n",
    "\n",
    "用公式表达：\n",
    "- 输入$\\mathbf{X}:c_i \\times n_h \\times n_w$\n",
    "- 核$\\mathbf{w}:c_i \\times k_h \\times k_w$\n",
    "- 输出$\\mathbf{y}:c_i \\times m_h \\times m_w$\n",
    "  \n",
    "$ \\mathbf{y} = \\sum_{i=0}^{c_i} \\mathbf{x}_{i,:,:} * \\mathbf{w}_{i,:,:} $\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3794134f-5b0d-4144-9530-493d39100026",
   "metadata": {},
   "source": [
    "代码实现多输入通道："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50392bd7-ddb1-4ee6-8856-9f8850b3bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    # 先遍历“X”和“K”的第0个维度（通道维度），再把它们加在一起\n",
    "    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c80b666-1d71-41f0-b562-335137a2b0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9581e1e5-7f96-4bea-a9b7-59363e03abfa",
   "metadata": {},
   "source": [
    "### 多输出通道\n",
    "无论有多少输入通道，到目前为止我们只用到单输出通道,\n",
    "我们可以有多个三维卷积核，每个核生成一个输出通道.\n",
    "\n",
    "用$c_i$和$c_o$分别表示输入和输出通道的数目，并让$k_h$和$k_w$为卷积核的高度和宽度。为了获得多个通道的输出，我们可以为每个输出通道创建一个形状为$c_i\\times k_h\\times k_w$的卷积核张量，这样卷积核的形状是$c_o\\times c_i\\times k_h\\times k_w$。在互相关运算中，每个输出通道先获取所有输入通道，再以对应该输出通道的卷积核计算出结果。\n",
    "\n",
    "用公式表达：\n",
    "- 输入$\\mathbf{X}:c_i \\times n_h \\times n_w$\n",
    "- 核$\\mathbf{w}:c_0 \\times c_i \\times k_h \\times k_w$\n",
    "- 输出$\\mathbf{y}:c_o \\times m_h \\times m_w$\n",
    "  \n",
    "$ \\mathbf{y_{i,:,:}} = \\mathbf{x} * \\mathbf{w}_{i,:,:,:}$ for $i = 1,...,c_0 $\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2efc65b4-b1bf-4ea0-9c44-bebcf4c97b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。\n",
    "    # 最后将所有结果都叠加在一起\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d3183-a8d7-427d-bb00-2aa9a8f866bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(K.shape)\n",
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "# print(K)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6599ae3-57df-4ef9-a8e6-efae1d740408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ac29c7-4ff4-433d-8ef5-c3ce697c3443",
   "metadata": {},
   "source": [
    "###  $1\\times 1$ 卷积层\n",
    "\n",
    "$1 \\times 1$卷积，即$k_h = k_w = 1$，是一个受欢迎的选择，经常包含在复杂深层网络的设计中。它不识别空间模式，只是融合通道。\n",
    "\n",
    "![互相关计算使用了具有3个输入通道和2个输出通道的 $1\\times 1$ 卷积核。其中，输入和输出具有相同的高度和宽度。](../image/conv-1x1.svg)\n",
    "\n",
    "相当于输入形状为$n_hn_w \\times c_i$,权重为$c_0 \\times c_i$的全连接层\n",
    "\n",
    "$1\\times 1$卷积层通常用于调整网络层的通道数量和控制模型复杂性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7671712-bec4-4307-b88f-c3181753ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    # 全连接层中的矩阵乘法\n",
    "    Y = torch.matmul(K, X)\n",
    "    return Y.reshape((c_o, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69304460-1590-4301-add5-faa1dcca7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.normal(0, 1, (3, 3, 3))\n",
    "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
    "\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63831b62-81cd-436b-9033-c0017ad6a75a",
   "metadata": {},
   "source": [
    "## 池化层\n",
    "本节将介绍池化（pooling）层（也可以叫汇聚层），它具有双重目的：降低卷积层对位置的敏感性，同时降低对空间降采样表示的敏感性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9099ea50-48fb-4386-b6ab-b09b3a4d954d",
   "metadata": {},
   "source": [
    "### 最大池化层和平均池化层\n",
    "\n",
    "与卷积层类似，汇聚层运算符由一个固定形状的窗口组成，该窗口根据其步幅大小在输入的所有区域上滑动，为固定形状窗口（有时称为汇聚窗口）遍历的每个位置计算一个输出。 然而，不同于卷积层中的输入与卷积核之间的互相关计算，汇聚层不包含参数。 相反，池运算是确定性的，我们通常计算汇聚窗口中所有元素的最大值或平均值。这些操作分别称为最大汇聚层（maximum pooling）和平均汇聚层（average pooling）。\n",
    "\n",
    "![汇聚窗口形状为 $2\\times 2$ 的最大汇聚层。着色部分是第一个输出元素，以及用于计算这个输出的输入元素: $\\max(0, 1, 3, 4)=4$.](http://d2l.ai/_images/pooling.svg)\n",
    "\n",
    "\n",
    "- 最大池化层:每个窗口中最强的模式信号\n",
    "- 平均池化层:将最大池化层中的“最大”操作替换为“平\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d00973-e62b-4738-a65b-e943b9f6bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现汇聚层的前向传播\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b58d77-16a4-4eab-920d-417fa650d8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e056cb2-142f-4be7-aa53-f99269e39c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, (2, 2), 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f88bd1-74ce-4828-b1a7-b34880cf96cc",
   "metadata": {},
   "source": [
    "### 填充，步幅和多个通道 \n",
    "\n",
    "- 池化层与卷积层类似，都具有填充和步幅\n",
    "- 没有可学习的参数\n",
    "- 在每个输入通道应用池化层以获得相应的输出通道\n",
    "- 输出通道数=输入通道数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73438be7-e0c2-4418-bc9a-3e8558515d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91fe2b60-1761-41ea-a283-4b7b07a835b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用框架里面的池化 \n",
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35f7ebfe-46ae-45f1-8b27-ee50c5e5e7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c455424a-f118-401f-a860-57c73402ed22",
   "metadata": {},
   "source": [
    "## 卷积神经网络（LeNet）\n",
    "\n",
    "**LeNet是早期成功的神经网络**。这个模型是由AT&T贝尔实验室的研究员Yann LeCun在1989年提出的（并以其命名），目的是识别图像 :cite:LeCun.Bottou.Bengio.ea.1998中的手写数字。 LeNet被广泛用于自动取款机（ATM）机中，帮助识别处理支票的数字。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16811713-bde6-4ed4-8cca-eef9f41cdfbf",
   "metadata": {},
   "source": [
    "### LeNet\n",
    "\n",
    "总体来看，(**LeNet（LeNet-5）由两个部分组成：**)(~~卷积编码器和全连接层密集块~~)\n",
    "\n",
    "* 卷积编码器：由两个卷积层组成;\n",
    "* 全连接层密集块：由三个全连接层组成。\n",
    "\n",
    "该架构如 :numref:`img_lenet`所示。\n",
    "\n",
    "![LeNet中的数据流。输入是手写数字，输出为10种可能结果的概率。](http://d2l.ai/_images/lenet.svg)\n",
    ":label:`img_lenet`\n",
    "\n",
    "- 每个卷积块中的基本单元是一个卷积层、一个sigmoid激活函数和平均汇聚层（ReLU和最大汇聚层更有效，但是当时还还没出现ReLu）。\n",
    "- 每个卷积层使用$5\\times 5$卷积核和一个sigmoid激活函数。这些层将输入映射到多个二维特征输出，通常同时增加通道的数量。\n",
    "- 第一卷积层有6个输出通道，而第二个卷积层有16个输出通道。\n",
    "- 每个$2\\times2$池操作（步幅2）通过空间下采样将维数减少4倍。卷积的输出形状由批量大小、通道数、高度、宽度决定。\n",
    "- LeNet的稠密块有三个全连接层，分别有120、84和10个输出。因为我们在执行分类任务，所以输出层的10维对应于最后输出结果的数量。\n",
    "\n",
    "![LeNet 的简化版。](../image/lenet-vert.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "933fe346-e450-483b-968b-a2d11f8678d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "# 代码实现 我们对原始模型做了一点小改动，去掉了最后一层的高斯激活。除此之外，这个网络与最初的LeNet-5一致。\n",
    "net = nn.Sequential(\n",
    "    # 1: 输入通道数。这意味着输入图像是单通道的，例如灰度图像。\n",
    "    # 6: 输出通道数。卷积层将输出6个特征图。\n",
    "    # kernel_size=5: 卷积核的大小是 5x5。\n",
    "    # padding=2: 在输入图像的边界周围添加2个像素的填充。\n",
    "    # nn.Sigmoid()：这是一个激活函数，用于将卷积层的输出进行非线性变换。\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e930917-e5c3-4882-9ac9-905c6410a9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape: \t torch.Size([1, 6, 28, 28])\n",
      "Sigmoid output shape: \t torch.Size([1, 6, 28, 28])\n",
      "AvgPool2d output shape: \t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape: \t torch.Size([1, 16, 10, 10])\n",
      "Sigmoid output shape: \t torch.Size([1, 16, 10, 10])\n",
      "AvgPool2d output shape: \t torch.Size([1, 16, 5, 5])\n",
      "Flatten output shape: \t torch.Size([1, 400])\n",
      "Linear output shape: \t torch.Size([1, 120])\n",
      "Sigmoid output shape: \t torch.Size([1, 120])\n",
      "Linear output shape: \t torch.Size([1, 84])\n",
      "Sigmoid output shape: \t torch.Size([1, 84])\n",
      "Linear output shape: \t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape: \\t',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d418aeba-de24-4e88-b692-0292b9087e73",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "看看LeNet在Fashion-MNIST数据集上的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "597c6e39-f292-4b59-9a3a-1345f032464b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ../data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ../data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ../data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ace6ede2-e091-40c4-bdb0-ac01f8573432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义评估函数 \n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None): #@save\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # 正确预测的数量，总预测的数量\n",
    "    metric = d2l.Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # BERT微调所需的（之后将介绍）\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(d2l.accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04a61b46-c8cc-4eb2-a6f9-0bc04940a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数train_ch6\n",
    "#@save\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"用GPU训练模型(在第六章定义)\"\"\"\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
    "                            legend=['train loss', 'train acc', 'test acc'])\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练损失之和，训练准确率之和，样本数\n",
    "        metric = d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            timer.stop()\n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (train_l, train_acc, None))\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
    "          f'on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e703ae2f-3ed0-4e5b-82a3-565524483ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.471, train acc 0.822, test acc 0.789\n",
      "10037.9 examples/sec on cuda:0\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-06-18T17:53:09.017148</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 183.35625 \n",
       "L 238.965625 183.35625 \n",
       "L 238.965625 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 30.103125 145.8 \n",
       "L 225.403125 145.8 \n",
       "L 225.403125 7.2 \n",
       "L 30.103125 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 51.803125 145.8 \n",
       "L 51.803125 7.2 \n",
       "\" clip-path=\"url(#pc76e2a0ebb)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"madfa811e8a\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#madfa811e8a\" x=\"51.803125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(48.621875 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 95.203125 145.8 \n",
       "L 95.203125 7.2 \n",
       "\" clip-path=\"url(#pc76e2a0ebb)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#madfa811e8a\" x=\"95.203125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(92.021875 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 138.603125 145.8 \n",
       "L 138.603125 7.2 \n",
       "\" clip-path=\"url(#pc76e2a0ebb)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#madfa811e8a\" x=\"138.603125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(135.421875 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 182.003125 145.8 \n",
       "L 182.003125 7.2 \n",
       "\" clip-path=\"url(#pc76e2a0ebb)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#madfa811e8a\" x=\"182.003125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 8 -->\n",
       "      <g transform=\"translate(178.821875 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 225.403125 145.8 \n",
       "L 225.403125 7.2 \n",
       "\" clip-path=\"url(#pc76e2a0ebb)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#madfa811e8a\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 30.103125 144.962316 \n",
       "L 225.403125 144.962316 \n",
       "\" clip-path=\"url(#pc76e2a0ebb)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <defs>\n",
       "       <path id=\"m4407592172\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4407592172\" x=\"30.103125\" y=\"144.962316\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(7.2 148.761535) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 30.103125 117.254648 \n",
       "L 225.403125 117.254648 \n",
       "\" clip-path=\"url(#pc76e2a0ebb)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4407592172\" x=\"30.103125\" y=\"117.254648\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.5 -->\n",
       "      <g transform=\"translate(7.2 121.053866) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 30.103125 89.546979 \n",
       "L 225.403125 89.546979 \n",
       "\" clip-path=\"url(#pc76e2a0ebb)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4407592172\" x=\"30.103125\" y=\"89.546979\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(7.2 93.346198) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 30.103125 61.83931 \n",
       "L 225.403125 61.83931 \n",
       "\" clip-path=\"url(#pc76e2a0ebb)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4407592172\" x=\"30.103125\" y=\"61.83931\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 1.5 -->\n",
       "      <g transform=\"translate(7.2 65.638529) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 30.103125 34.131642 \n",
       "L 225.403125 34.131642 \n",
       "\" clip-path=\"url(#pc76e2a0ebb)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4407592172\" x=\"30.103125\" y=\"34.131642\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 2.0 -->\n",
       "      <g transform=\"translate(7.2 37.93086) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_21\">\n",
       "    <path d=\"M 12.743125 13.5 \n",
       "L 17.083125 15.153309 \n",
       "L 21.423125 15.771631 \n",
       "L 25.763125 16.127106 \n",
       "L 30.103125 16.348356 \n",
       "L 34.443125 17.332981 \n",
       "L 38.783125 17.410139 \n",
       "L 43.123125 17.798688 \n",
       "L 47.463125 23.762293 \n",
       "L 51.803125 33.4396 \n",
       "L 56.143125 83.898442 \n",
       "L 60.483125 86.587403 \n",
       "L 64.823125 88.004947 \n",
       "L 69.163125 90.08526 \n",
       "L 73.503125 91.558304 \n",
       "L 77.843125 99.321265 \n",
       "L 82.183125 101.040564 \n",
       "L 86.523125 101.920189 \n",
       "L 90.863125 102.781815 \n",
       "L 95.203125 103.588992 \n",
       "L 99.543125 106.043147 \n",
       "L 103.883125 107.125786 \n",
       "L 108.223125 107.5304 \n",
       "L 112.563125 108.104773 \n",
       "L 116.903125 108.425403 \n",
       "L 121.243125 110.877056 \n",
       "L 125.583125 110.856702 \n",
       "L 129.923125 111.121874 \n",
       "L 134.263125 111.442156 \n",
       "L 138.603125 111.758922 \n",
       "L 142.943125 113.99239 \n",
       "L 147.283125 113.894874 \n",
       "L 151.623125 113.740627 \n",
       "L 155.963125 114.112307 \n",
       "L 160.303125 114.189916 \n",
       "L 164.643125 115.400275 \n",
       "L 168.983125 115.542933 \n",
       "L 173.323125 115.947916 \n",
       "L 177.663125 115.955515 \n",
       "L 182.003125 116.089208 \n",
       "L 186.343125 117.382392 \n",
       "L 190.683125 117.324622 \n",
       "L 195.023125 117.395233 \n",
       "L 199.363125 117.518696 \n",
       "L 203.703125 117.629406 \n",
       "L 208.043125 117.901224 \n",
       "L 212.383125 118.535891 \n",
       "L 216.723125 118.649529 \n",
       "L 221.063125 118.74046 \n",
       "L 225.403125 118.863705 \n",
       "\" clip-path=\"url(#pc76e2a0ebb)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_22\">\n",
       "    <path d=\"M 12.743125 139.417098 \n",
       "L 17.083125 139.414795 \n",
       "L 21.423125 139.320379 \n",
       "L 25.763125 139.295048 \n",
       "L 30.103125 139.302563 \n",
       "L 34.443125 139.5 \n",
       "L 38.783125 139.276625 \n",
       "L 43.123125 138.448374 \n",
       "L 47.463125 136.337061 \n",
       "L 51.803125 132.807886 \n",
       "L 56.143125 115.246579 \n",
       "L 60.483125 114.019169 \n",
       "L 64.823125 113.075776 \n",
       "L 69.163125 111.971952 \n",
       "L 73.503125 111.243007 \n",
       "L 77.843125 107.430768 \n",
       "L 82.183125 106.592538 \n",
       "L 86.523125 106.242507 \n",
       "L 90.863125 105.920111 \n",
       "L 95.203125 105.622045 \n",
       "L 99.543125 104.823963 \n",
       "L 103.883125 104.434785 \n",
       "L 108.223125 104.285101 \n",
       "L 112.563125 104.0813 \n",
       "L 116.903125 103.94296 \n",
       "L 121.243125 102.746809 \n",
       "L 125.583125 102.80438 \n",
       "L 129.923125 102.802077 \n",
       "L 134.263125 102.614396 \n",
       "L 138.603125 102.488307 \n",
       "L 142.943125 101.595393 \n",
       "L 147.283125 101.60921 \n",
       "L 151.623125 101.659873 \n",
       "L 155.963125 101.481403 \n",
       "L 160.303125 101.460353 \n",
       "L 164.643125 100.973629 \n",
       "L 168.983125 100.929875 \n",
       "L 173.323125 100.741811 \n",
       "L 177.663125 100.752557 \n",
       "L 182.003125 100.652213 \n",
       "L 186.343125 100.430161 \n",
       "L 190.683125 100.291991 \n",
       "L 195.023125 100.14768 \n",
       "L 199.363125 100.075525 \n",
       "L 203.703125 99.983534 \n",
       "L 208.043125 99.808396 \n",
       "L 212.383125 99.573507 \n",
       "L 216.723125 99.58886 \n",
       "L 221.063125 99.504422 \n",
       "L 225.403125 99.433999 \n",
       "\" clip-path=\"url(#pc76e2a0ebb)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_23\">\n",
       "    <path d=\"M 30.103125 139.420783 \n",
       "L 51.803125 120.274784 \n",
       "L 73.503125 108.005828 \n",
       "L 95.203125 105.48443 \n",
       "L 116.903125 103.068321 \n",
       "L 138.603125 103.328773 \n",
       "L 160.303125 101.04012 \n",
       "L 182.003125 100.884957 \n",
       "L 203.703125 100.884957 \n",
       "L 225.403125 101.234074 \n",
       "\" clip-path=\"url(#pc76e2a0ebb)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 30.103125 145.8 \n",
       "L 30.103125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 225.403125 145.8 \n",
       "L 225.403125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 30.103125 145.8 \n",
       "L 225.403125 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 30.103125 7.2 \n",
       "L 225.403125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 140.634375 59.234375 \n",
       "L 218.403125 59.234375 \n",
       "Q 220.403125 59.234375 220.403125 57.234375 \n",
       "L 220.403125 14.2 \n",
       "Q 220.403125 12.2 218.403125 12.2 \n",
       "L 140.634375 12.2 \n",
       "Q 138.634375 12.2 138.634375 14.2 \n",
       "L 138.634375 57.234375 \n",
       "Q 138.634375 59.234375 140.634375 59.234375 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_24\">\n",
       "     <path d=\"M 142.634375 20.298438 \n",
       "L 152.634375 20.298438 \n",
       "L 162.634375 20.298438 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_12\">\n",
       "     <!-- train loss -->\n",
       "     <g transform=\"translate(170.634375 23.798438) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"264.550781\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"292.333984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"353.515625\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"405.615234\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_25\">\n",
       "     <path d=\"M 142.634375 34.976563 \n",
       "L 152.634375 34.976563 \n",
       "L 162.634375 34.976563 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- train acc -->\n",
       "     <g transform=\"translate(170.634375 38.476563) scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"264.550781\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"325.830078\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"380.810547\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_26\">\n",
       "     <path d=\"M 142.634375 49.654688 \n",
       "L 152.634375 49.654688 \n",
       "L 162.634375 49.654688 \n",
       "\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- test acc -->\n",
       "     <g transform=\"translate(170.634375 53.154688) scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"100.732422\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"152.832031\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"192.041016\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"223.828125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"285.107422\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"340.087891\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pc76e2a0ebb\">\n",
       "   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 开始训练 \n",
    "lr, num_epochs = 0.9, 10\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a0dab9-1660-4bba-8720-3463ed9c3b48",
   "metadata": {},
   "source": [
    "### 小结\n",
    "\n",
    "* 卷积神经网络（CNN）是一类使用卷积层的网络。\n",
    "* 在卷积神经网络中，我们组合使用卷积层、非线性激活函数和汇聚层。\n",
    "* 为了构造高性能的卷积神经网络，我们通常对卷积层进行排列，逐渐降低其表示的空间分辨率，同时增加通道数。\n",
    "* 在传统的卷积神经网络中，卷积块编码得到的表征在输出之前需由一个或多个全连接层进行处理。\n",
    "* LeNet是最早发布的卷积神经网络之一。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
