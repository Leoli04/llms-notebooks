{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e5ae4c5-0034-49f2-b42d-4b94590ae807",
   "metadata": {},
   "source": [
    "# 现代卷积神经网络\n",
    "\n",
    "本章将介绍现代的卷积神经网络架构，许多现代卷积神经网络的研究都是建立在这一章的基础上的。 在本章中的每一个模型都曾一度占据主导地位，其中许多模型都是ImageNet竞赛的优胜者。ImageNet竞赛自2010年以来，一直是计算机视觉中监督学习进展的指向标。\n",
    "\n",
    "这些模型包括：\n",
    "- AlexNet(深度卷积神经网络)。它是第一个在大规模视觉竞赛中击败传统计算机视觉模型的大型神经网络；\n",
    "- 使用重复块的网络（VGG）。它利用许多重复的神经网络块；\n",
    "- 网络中的网络（NiN）。它重复使用由卷积层和$1 \\times 1$卷积层（用来代替全连接层）来构建深层网络;\n",
    "- 含并行连结的网络（GoogLeNet）。它使用并行连结的网络，通过不同窗口大小的卷积层和最大汇聚层来并行抽取信息；\n",
    "- 残差网络（ResNet）。它通过残差块构建跨层的数据通道，是计算机视觉中最流行的体系架构；\n",
    "- 稠密连接网络（DenseNet）。它的计算成本很高，但给我们带来了更好的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a658faa0-a376-430b-b9eb-32c29a888a6b",
   "metadata": {},
   "source": [
    "## 深度卷积神经网络（AlexNet）\n",
    "\n",
    "早期机器学习的流水线看起来更像下面这样：\n",
    "1. 获取一个有趣的数据集。在早期，收集这些数据集需要昂贵的传感器（在当时最先进的图像也就100万像素）。\n",
    "2. 根据光学、几何学、其他知识以及偶然的发现，手工对特征数据集进行预处理。\n",
    "3. 通过标准的特征提取算法，如SIFT（尺度不变特征变换） :cite:`Lowe.2004`和SURF（加速鲁棒特征） :cite:`Bay.Tuytelaars.Van-Gool.2006`或其他手动调整的流水线来输入数据。\n",
    "4. 将提取的特征送入最喜欢的分类器中（例如线性模型或其它核方法），以训练分类器。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a65e6-a337-44ec-b411-44a8f1e9c6ab",
   "metadata": {},
   "source": [
    "### 学习图像特征\n",
    "\n",
    "在2012年前，图像特征都是机械地计算出来的。\n",
    "同时也缺少数据（许多数据集只有几百至几千张在非自然环境下以低分辨率拍摄的图像）和硬件（还没GPU）支持。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1c91db-d8b3-4ee8-a093-bfa6daa18021",
   "metadata": {},
   "source": [
    "#### GPU vs CPU\n",
    "中央处理器（Central Processing Unit，CPU）的每个核心都拥有高时钟频率的运行能力，和高达数MB的三级缓存（L3Cache）。 它们非常适合执行各种指令，具有分支预测器、深层流水线和其他使CPU能够运行各种程序的功能。 然而，这种明显的优势也是它的致命弱点：通用核心的制造成本非常高。 它们需要大量的芯片面积、复杂的支持结构（内存接口、内核之间的缓存逻辑、高速互连等等），而且它们在任何单个任务上的性能都相对较差。\n",
    "\n",
    "GPU由$100 \\sim 1000$个小的处理单元组成（NVIDIA、ATI、ARM和其他芯片供应商之间的细节稍有不同），通常被分成更大的组（NVIDIA称之为warps）。\n",
    "虽然每个GPU核心都相对较弱，有时甚至以低于1GHz的时钟频率运行，但庞大的核心数量使GPU比CPU快几个数量级。\n",
    "\n",
    "首先，功耗往往会随时钟频率呈二次方增长。\n",
    "对于一个CPU核心，假设它的运行速度比GPU快4倍，但可以使用16个GPU核代替，那么GPU的综合性能就是CPU的$16 \\times 1/4 = 4$倍。\n",
    "其次，GPU内核要简单得多，这使得它们更节能。\n",
    "此外，深度学习中的许多操作需要相对较高的内存带宽，而GPU拥有10倍于CPU的带宽。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab8d659-68ac-4f92-bca8-047d5ad7e20c",
   "metadata": {},
   "source": [
    "### AlexNet\n",
    "\n",
    "2012年，赢得了2012年ImageNet图像识别挑战赛。\n",
    "它首次证明了学习到的特征可以超越手工设计的特征。\n",
    "\n",
    "\n",
    "![从LeNet（左）到AlexNet（右）](../image/alexnet.svg)\n",
    "\n",
    "AlexNet和LeNet的设计理念非常相似，但也存在显著差异。\n",
    "\n",
    "**1. AlexNet比相对较小的LeNet5要深得多。AlexNet由八层组成：五个卷积层、两个全连接隐藏层和一个全连接输出层。\n",
    "2. AlexNet使用ReLU而不是sigmoid作为其激活函数。**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2e72fc-990f-4f3c-80d0-be0bd801cd1e",
   "metadata": {},
   "source": [
    "#### 模型设计\n",
    "\n",
    "- **在AlexNet的第一层，卷积窗口的形状是$11\\times11$**。\n",
    "由于ImageNet中大多数图像的宽和高比MNIST图像的多10倍以上，因此，需要一个更大的卷积窗口来捕获目标。\n",
    "- **第二层中的卷积窗口形状被缩减为$5\\times5$，然后是$3\\times3$***。\n",
    "- 此外，**在第一层、第二层和第五层卷积层之后，加入窗口形状为$3\\times3$、步幅为2的最大汇聚层**。\n",
    "而且，AlexNet的卷积通道数目是LeNet的10倍。\n",
    "\n",
    "在最后一个卷积层后有两个全连接层，分别有4096个输出。\n",
    "这两个巨大的全连接层拥有将近1GB的模型参数。\n",
    "\n",
    "> 由于早期GPU显存有限，原版的AlexNet采用了双数据流设计，使得每个GPU只负责存储和计算模型的一半参数。\n",
    "幸运的是，现在GPU显存相对充裕，所以现在很少需要跨GPU分解模型（因此，本书的AlexNet模型在这方面与原始论文稍有不同）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d727384d-4918-47b6-9577-553fbfe5158b",
   "metadata": {},
   "source": [
    "#### 激活函数\n",
    "\n",
    "**AlexNet将sigmoid激活函数改为更简单的ReLU激活函数。**\n",
    "一方面，ReLU激活函数的计算更简单，它不需要如sigmoid激活函数那般复杂的求幂运算。\n",
    "另一方面，当使用不同的参数初始化方法时，ReLU激活函数使训练模型更加容易。\n",
    "当sigmoid激活函数的输出非常接近于0或1时，这些区域的梯度几乎为0，因此反向传播无法继续更新一些模型参数。\n",
    "相反，ReLU激活函数在正区间的梯度总是1。\n",
    "因此，如果模型参数没有正确初始化，sigmoid函数可能在正区间内得到几乎为0的梯度，从而使模型无法得到有效的训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f151b888-6bba-451b-b537-6b0c742b1660",
   "metadata": {},
   "source": [
    "#### 容量控制和预处理\n",
    "\n",
    "**AlexNet通过丢弃法控制全连接层的模型复杂度，而LeNet只使用了权重衰减。**\n",
    "**为了进一步扩充数据，AlexNet在训练时增加了大量的图像增强数据，如翻转、裁切和变色。**\n",
    "这使得模型更健壮，更大的样本量有效地减少了过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e19c18-291e-4f70-b597-1651f1fcca1f",
   "metadata": {},
   "source": [
    "### 代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a69577-8bf3-4a6b-b6a2-676470bcce80",
   "metadata": {},
   "source": [
    "#### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f63d205-273c-4743-a4f8-016496a1e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "net = nn.Sequential(\n",
    "    # 这里使用一个11*11的更大窗口来捕捉对象。\n",
    "    # 同时，步幅为4，以减少输出的高度和宽度。\n",
    "    # 另外，输出通道的数目远大于LeNet\n",
    "    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 使用三个连续的卷积层和较小的卷积窗口。\n",
    "    # 除了最后的卷积层，输出通道的数量进一步增加。\n",
    "    # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度\n",
    "    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Flatten(),\n",
    "    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合\n",
    "    nn.Linear(6400, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(4096, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "    nn.Linear(4096, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858b0a9-3abd-4994-bb8f-391e3c52598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(1, 1, 224, 224)\n",
    "for layer in net:\n",
    "    X=layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddf6550-99d6-49ec-9432-fac79d840689",
   "metadata": {},
   "source": [
    "解释第一次shape变化`Conv2d output shape:\t torch.Size([1, 96, 54, 54])`\n",
    "- `nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1)`表示\n",
    "    输入通道数为1,输出通道数为96,卷积核大小为11x11,步长为4,填充为1\n",
    "- 输入`X = torch.randn(1, 1, 224, 224)`,其形状表示\n",
    "    批量大小为1,输入通道数为1,图像高度为224,图像宽度为224\n",
    "- 卷积操作后的输出尺寸可以通过以下公式计算\n",
    "```\n",
    "output_height = (input_height - kernel_height + 2 * padding_height) // stride_height + 1  \n",
    "output_width = (input_width - kernel_width + 2 * padding_width) // stride_width + 1\n",
    "```\n",
    "```\n",
    "output_height = (224 - 11 + 2 * 1) // 4 + 1 = 54  \n",
    "output_width = (224 - 11 + 2 * 1) // 4 + 1 = 54\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40b380-b0e5-4457-b1e6-cfdb4337c716",
   "metadata": {},
   "source": [
    "#### 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d88314c-386b-4e51-8e2b-1b15b15c6f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dca1c4-ac4d-4a3b-ad04-93d7d5062c55",
   "metadata": {},
   "source": [
    "#### 训练AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0f3b40-c241-4d72-8091-720e0ab9941a",
   "metadata": {},
   "source": [
    "lr, num_epochs = 0.01, 10\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d70242-8a7c-4b92-b49c-84dcc1db0417",
   "metadata": {},
   "source": [
    "### 小结\n",
    "\n",
    "* AlexNet的架构与LeNet相似，但使用了更多的卷积层和更多的参数来拟合大规模的ImageNet数据集（10x参数个数，260x计算复杂度）。\n",
    "* 今天，AlexNet已经被更有效的架构所超越，但它是从浅层网络到深层网络的关键一步。\n",
    "* 尽管AlexNet的代码只比LeNet多出几行，但学术界花了很多年才接受深度学习这一概念，并应用其出色的实验结果。这也是由于缺乏有效的计算工具。\n",
    "* Dropout、ReLU和预处理是提升计算机视觉任务性能的其他关键步骤。\n",
    "* 虽然AlexNet证明深层神经网络卓有成效，但它没有提供一个通用的模板来指导后续的研究人员设计新的网络。 在下面的几个章节中，我们将介绍一些常用于设计深层神经网络的启发式概念。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd13969-0c37-489c-b096-39605ff27cdd",
   "metadata": {},
   "source": [
    "## 使用块的网络（VGG）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1127215-95f8-492b-a0cf-d1e753ef4e5a",
   "metadata": {},
   "source": [
    "### VGG块\n",
    "VGG块由一系列卷积层组成，后面再加上用于空间下采样的最大汇聚层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "106053a2-3eb5-4dba-af9d-584a6eaa58f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "# 卷积层的数量num_convs、输入通道的数量in_channels 和输出通道的数量out_channels\n",
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels,\n",
    "                                kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels = out_channels\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96ef96d-458d-49fc-aca4-38c354da3355",
   "metadata": {},
   "source": [
    "### VGG网络\n",
    "与AlexNet、LeNet一样，VGG网络可以分为两部分：第一部分主要由卷积层和汇聚层组成，第二部分由全连接层组成。\n",
    "\n",
    "![从AlexNet到VGG，它们本质上都是块设计。](../image/vgg.svg)\n",
    "\n",
    "**在VGG中有个超参数变量conv_arch。该变量指定了每个VGG块里卷积层个数和输出通道数**。全连接模块则与AlexNet中的相同。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f837d1-787e-48e5-bfa4-2e458d114d65",
   "metadata": {},
   "source": [
    "#### 对比\n",
    "\n",
    "- LeNet (1995)：2 卷积+池化层；2全连接层\n",
    "- AlexNet：更大更深；ReLu,Dropout,数据增强\n",
    "- VGG：更大更深的 AlexNet(重复的 VGG 块)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa6919-fb15-496a-a25f-d828dc34661a",
   "metadata": {},
   "source": [
    "原始VGG网络有5个卷积块，其中前两个块各有一个卷积层，后三个块各包含两个卷积层。 第一个模块有64个输出通道，每个后续模块将输出通道数量翻倍，直到该数字达到512。由于该网络使用8个卷积层和3个全连接层，因此它通常被称为VGG-11。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c30f3ba-8911-432c-a3e5-9a319598114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面的代码实现了VGG-11\n",
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))\n",
    "def vgg(conv_arch):\n",
    "    conv_blks = []\n",
    "    in_channels = 1\n",
    "    # 卷积层部分\n",
    "    for (num_convs, out_channels) in conv_arch:\n",
    "        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "        in_channels = out_channels\n",
    "\n",
    "    return nn.Sequential(\n",
    "        *conv_blks, nn.Flatten(),\n",
    "        # 全连接层部分\n",
    "        nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 10))\n",
    "\n",
    "net = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0ea3ef4-b705-455a-a871-f64a0a727d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 112, 112])\n",
      "Sequential output shape:\t torch.Size([1, 128, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 256, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 512, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "Flatten output shape:\t torch.Size([1, 25088])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# 观察每个层输出的形状\n",
    "X = torch.randn(size=(1, 1, 224, 224))\n",
    "for blk in net:\n",
    "    X = blk(X)\n",
    "    print(blk.__class__.__name__,'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266d3d4a-d686-454f-b5da-65d7cddba0da",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690445c1-e124-40db-a983-3f7290422482",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 4\n",
    "small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]\n",
    "net = vgg(small_conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4d8ce-e68c-4030-bd23-e70e62ff085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size = 0.05, 10, 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bf343d-2517-40f6-98ed-5861c9d4dd11",
   "metadata": {},
   "source": [
    "- VGG使用可重复使用的卷积块来构建深度卷积神经网络\n",
    "- 不同的卷积块个数和超参数可以得到不同复杂度的变种,如VGG-16,CGG-19\n",
    "- 块的使用导致网络定义的非常简洁。使用块可以有效地设计复杂的网络。\n",
    "- 在VGG论文中，Simonyan和Ziserman尝试了各种架构。特别是他们发现**深层且窄的卷积（即$3 \\times 3$\n",
    "）比较浅层且宽的卷积更有效**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73330ca5-8361-4394-b68c-ed3652d8b0e7",
   "metadata": {},
   "source": [
    "## 网络中的网络（NiN）\n",
    "\n",
    "LeNet、AlexNet和VGG都有一个共同的设计模式：通过一系列的卷积层与汇聚层来提取空间结构特征；然后通过全连接层对特征的表征进行处理。 AlexNet和VGG对LeNet的改进主要在于如何扩大和加深这两个模块。\n",
    "\n",
    " 网络中的网络（NiN）提供了一个非常简单的解决方案：在每个像素的通道上分别使用多层感知机"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9512bb1-59a8-4d76-97fb-7a989ddc4666",
   "metadata": {},
   "source": [
    "### NiN块\n",
    "卷积层的输入和输出由四维张量组成，张量的每个轴分别对应样本、通道、高度和宽度。 \n",
    "全连接层的输入和输出通常是分别对应于样本和特征的二维张量。 \n",
    "NiN的想法是在每个像素位置（针对每个高度和宽度）应用一个全连接层。 如果我们将权重连接到每个空间位置，我们可以将其视为$1 \\times 1$卷积层,即将空间维度中的每个像素视为单个样本，将通道维度视为不同特征（feature）。\n",
    "\n",
    "\n",
    "![对比 VGG 和 NiN 及它们的块之间主要架构差异。](http://d2l.ai/_images/nin.svg)\n",
    "\n",
    "NiN块以一个普通卷积层开始，后面是两个$1 \\times 1$的卷积层。这两个$1 \\times 1$卷积层充当带有ReLU激活函数的逐像素全连接层。\n",
    "第一层的卷积窗口形状通常由用户设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7348e4b4-a93f-4d64-a04a-3faee923bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "def nin_block(in_channels, out_channels, kernel_size, strides, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4517896b-73cd-47fb-8a4b-89d2d987a1a3",
   "metadata": {},
   "source": [
    "### NiN模型\n",
    "\n",
    "NiN使用窗口形状为$11\\times 11$、$5\\times 5$和$3\\times 3$的卷积层，输出通道数量与AlexNet中的相同。\n",
    "每个NiN块后有一个最大汇聚层，汇聚窗口形状为$3\\times 3$，步幅为2。\n",
    "\n",
    "NiN和AlexNet之间的一个显著区别是NiN完全取消了全连接层。\n",
    "相反，NiN使用一个NiN块，其输出通道数等于标签类别的数量。最后放一个*全局平均汇聚层*（global average pooling layer），生成一个对数几率\t（logits）。NiN设计的一个优点是，它显著减少了模型所需参数的数量。然而，在实践中，这种设计有时会增加训练模型的时间。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a10320d-03dc-4e63-bb2d-c8c9fb4c41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nin_block(1, 96, kernel_size=11, strides=4, padding=0),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nin_block(96, 256, kernel_size=5, strides=1, padding=2),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nin_block(256, 384, kernel_size=3, strides=1, padding=1),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nn.Dropout(0.5),\n",
    "    # 标签类别数是10\n",
    "    nin_block(384, 10, kernel_size=3, strides=1, padding=1),\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    # 将四维的输出转成二维的输出，其形状为(批量大小,10)\n",
    "    nn.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3251abdd-d0e8-498b-9cfe-34fdea3341d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 96, 54, 54])\n",
      "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
      "Sequential output shape:\t torch.Size([1, 256, 26, 26])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "Sequential output shape:\t torch.Size([1, 384, 12, 12])\n",
      "MaxPool2d output shape:\t torch.Size([1, 384, 5, 5])\n",
      "Dropout output shape:\t torch.Size([1, 384, 5, 5])\n",
      "Sequential output shape:\t torch.Size([1, 10, 5, 5])\n",
      "AdaptiveAvgPool2d output shape:\t torch.Size([1, 10, 1, 1])\n",
      "Flatten output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1, 224, 224))\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6445006e-faff-48c8-a1fc-58eae366410a",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf8a995-0507-4c5c-a1e2-65352ea2af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size = 0.1, 10, 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482824b-316a-416e-848d-e4db01a34053",
   "metadata": {},
   "source": [
    "### 小结\n",
    "\n",
    "* NiN使用由一个卷积层和多个$1\\times 1$卷积层组成的块。该块可以在卷积神经网络中使用，以允许更多的每像素非线性。\n",
    "* NiN去除了容易造成过拟合的全连接层，将它们替换为全局平均汇聚层（即在所有位置上进行求和）。该汇聚层通道数量为所需的输出数量（例如，Fashion-MNIST的输出为10）。\n",
    "* 移除全连接层可减少过拟合，同时显著减少NiN的参数。\n",
    "* NiN的设计影响了许多后续卷积神经网络的设计。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0a61b6-8b06-461f-a501-be5c115d4b5b",
   "metadata": {},
   "source": [
    "## 含并行连结的网络（GoogLeNet）\n",
    "先回顾前面的神经网络参数：\n",
    "![不同cnn架构参数](../image/cnn_param_vs.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5e33a0-475f-4053-89c4-d285799e2436",
   "metadata": {},
   "source": [
    "### Inception块\n",
    "在GoogLeNet中，基本的卷积块被称为Inception块（Inception block）。\n",
    "\n",
    "![Inception块的架构。](../image/inception.svg)\n",
    "\n",
    "Inception块由四条并行路径组成。\n",
    "前三条路径使用窗口大小为$1\\times 1$、$3\\times 3$和$5\\times 5$的卷积层，从不同空间大小中提取信息。\n",
    "中间的两条路径在输入上执行$1\\times 1$卷积，以减少通道数，从而降低模型的复杂性。\n",
    "第四条路径使用$3\\times 3$最大汇聚层，然后使用$1\\times 1$卷积层来改变通道数。\n",
    "这四条路径都使用合适的填充来使输入与输出的高和宽一致，最后我们将每条线路的输出在通道维度上连结，并构成Inception块的输出。在Inception块中，通常调整的超参数是每层输出通道数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3653b884-4231-4da5-b350-c17e0f0a3770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    # c1--c4是每条路径的输出通道数\n",
    "    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        # 线路1，单1x1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # 线路2，1x1卷积层后接3x3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1x1卷积层后接5x5卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # 线路4，3x3最大汇聚层后接1x1卷积层\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        # 在通道维度上连结输出\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38db8aae-cef6-4c57-beb2-8136290224a7",
   "metadata": {},
   "source": [
    "### GoogLeNet模型\n",
    "GoogLeNet一共使用9个Inception块和全局平均汇聚层的堆叠来生成其估计值。Inception块之间的最大汇聚层可降低维度。 第一个模块类似于AlexNet和LeNet，Inception块的组合从VGG继承，全局平均汇聚层避免了在最后使用全连接层。\n",
    "\n",
    "![GoogLeNet架构。](../image/inception-full.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c441ab-17c4-4893-97a8-5654ab0e0010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "885ac336-f653-466b-ab3e-73b13c269017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一个模块使用64个通道、7X7卷积层。\n",
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "# 第二个模块使用两个卷积层：第一个卷积层是64个通道、1X1卷积层；\n",
    "# 第二个卷积层使用将通道数量增加三倍的3X3卷积层。 \n",
    "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "# 第三个模块串联两个完整的Inception块。 第一个Inception块的输出通道数为64+128+32+32=256\n",
    "# 其中第二个和第三个路径首先将输入通道的数量分别减少到96/192=1/2 和 16/192=1/12\n",
    "# 第二个Inception块的输出通道数增加到128+192+96+64=480\n",
    "b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "                   Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "# 第四模块更加复杂， 它串联了5个Inception块，\n",
    "b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "                   Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "                   Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "                   Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "                   Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "# 第五模块包含输出通道数为256+320+128+128=832和384+384+128+128=1024\n",
    "b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "                   Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "                   nn.AdaptiveAvgPool2d((1,1)),\n",
    "                   nn.Flatten())\n",
    "\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10a6c8ae-cea2-476a-9a39-0baad20a17dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 24, 24])\n",
      "Sequential output shape:\t torch.Size([1, 192, 12, 12])\n",
      "Sequential output shape:\t torch.Size([1, 480, 6, 6])\n",
      "Sequential output shape:\t torch.Size([1, 832, 3, 3])\n",
      "Sequential output shape:\t torch.Size([1, 1024])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# GoogLeNet模型的计算复杂，而且不如VGG那样便于修改通道数。 为了使Fashion-MNIST上的训练短小精悍，我们将输入的高和宽从224降到96，\n",
    "X = torch.rand(size=(1, 1, 96, 96))\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d90303-94bc-4a10-be87-5635970a1890",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28648fe-dee3-4afd-a227-555d5d3b0120",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size = 0.1, 10, 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717c5a9a-c002-4775-9380-786209530aab",
   "metadata": {},
   "source": [
    "### Inception后续变种\n",
    "- Inception-BN(v2)-使用 batch normalization\n",
    "- Inception-V3-修改了Inception块\n",
    "    - 替换 5x5 为多个 3x3 卷积层\n",
    "    - 替换 5x5 为 1x7 和 7x1 卷积层\n",
    "    - 替换 3x3 为 1x3 和 3x1 卷积层\n",
    "    - 更深\n",
    "- Inception-V4-使用残差连接"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68d8bb8-d082-4321-8799-035cf16254a4",
   "metadata": {},
   "source": [
    "### 小结\n",
    "\n",
    "* Inception块相当于一个有4条路径的子网络。它通过不同窗口形状的卷积层和最大汇聚层来并行抽取信息，并使用$1×1$卷积层减少每像素级别上的通道维数从而降低模型复杂度。\n",
    "*  GoogLeNet将多个设计精细的Inception块与其他层（卷积层、全连接层）串联起来。其中Inception块的通道数分配之比是在ImageNet数据集上通过大量的实验得来的。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a81c58a-1ca7-49bc-9d8f-ef043ca98b92",
   "metadata": {},
   "source": [
    "## 批量规范化(batch normalization)\n",
    "\n",
    "批量规范化（batch normalization）可持续加速深层网络的收敛速度。\n",
    "\n",
    "原理：在每次训练迭代中，我们首先规范化输入，即通过减去其均值并除以其标准差，其中两者均基于当前小批量处理。 接下来，我们应用比例系数和比例偏移。 正是由于这个基于批量统计的标准化，才有了批量规范化的名称。\n",
    "\n",
    "\n",
    "从形式上来说，用$\\mathbf{x} \\in \\mathcal{B}$表示一个来自小批量$\\mathcal{B}$的输入，批量规范化$\\mathrm{BN}$根据以下表达式转换$\\mathbf{x}$：\n",
    "\n",
    "$$\\mathrm{BN}(\\mathbf{x}) = \\boldsymbol{\\gamma} \\odot \\frac{\\mathbf{x} - \\hat{\\boldsymbol{\\mu}}_\\mathcal{B}}{\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}} + \\boldsymbol{\\beta}.$$\n",
    ":eqlabel:`eq_batchnorm`\n",
    "\n",
    "在 :eqref:`eq_batchnorm`中，$\\hat{\\boldsymbol{\\mu}}_\\mathcal{B}$是小批量$\\mathcal{B}$的样本均值，$\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}$是小批量$\\mathcal{B}$的样本标准差。\n",
    "应用标准化后，生成的小批量的平均值为0和单位方差为1。\n",
    "由于单位方差（与其他一些魔法数）是一个主观的选择，因此我们通常包含\n",
    "*拉伸参数*（scale）$\\boldsymbol{\\gamma}$和*偏移参数*（shift）$\\boldsymbol{\\beta}$，它们的形状与$\\mathbf{x}$相同。\n",
    "请注意，$\\boldsymbol{\\gamma}$和$\\boldsymbol{\\beta}$是需要与其他模型参数一起学习的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c6ec92-1c43-464a-8177-0b138ab1c0bf",
   "metadata": {},
   "source": [
    "### 批量规范化层\n",
    "批量规范化和其他层之间的一个关键区别是，由于批量规范化在完整的小批量上运行，因此我们不能像以前在引入其他层时那样忽略批量大小。\n",
    "**- 对于全连接层，作用的特征维**\n",
    "**- 对于卷积层，作用在通道维**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccc15c6-6e67-4378-bc60-dd8de613851f",
   "metadata": {},
   "source": [
    "#### 全连接层\n",
    "\n",
    "通常，我们将批量规范化层置于全连接层中的仿射变换和激活函数之间。\n",
    "设全连接层的输入为x，权重参数和偏置参数分别为$\\mathbf{W}$和$\\mathbf{b}$，激活函数为$\\phi$，批量规范化的运算符为$\\mathrm{BN}$。\n",
    "那么，使用批量规范化的全连接层的输出的计算详情如下：\n",
    "\n",
    "$$\\mathbf{h} = \\phi(\\mathrm{BN}(\\mathbf{W}\\mathbf{x} + \\mathbf{b}) ).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d306d5f8-46bc-47cf-b2f5-cd80227f6bc0",
   "metadata": {},
   "source": [
    "#### 卷积层\n",
    "\n",
    "同样，对于卷积层，我们可以在卷积层之后和非线性激活函数之前应用批量规范化。\n",
    "当卷积有多个输出通道时，我们需要对这些通道的“每个”输出执行批量规范化，每个通道都有自己的拉伸（scale）和偏移（shift）参数，这两个参数都是标量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd425bdf-581e-4397-a7c2-9028237fe614",
   "metadata": {},
   "source": [
    "### 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b749d74-7f84-4263-9ef3-9017917e4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "# X: 输入数据，可以是一个二维张量（对于全连接层）或一个四维张量（对于卷积层）。\n",
    "# gamma 和 beta: 这两个是可学习的缩放和偏移参数，用于在归一化后对数据进行调整。\n",
    "# moving_mean 和 moving_var: 这两个是移动平均的均值和方差，用于在推理（或评估）阶段进行归一化。\n",
    "# eps: 一个小的正数，用于防止分母为零，确保数值稳定性。\n",
    "# momentum: 用于计算移动平均的动量值，通常接近1（如0.9或0.99）。\n",
    "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    # 通过is_grad_enabled来判断当前模式是训练模式还是预测模式\n",
    "    if not torch.is_grad_enabled():\n",
    "        # 如果是在预测模式下，直接使用传入的移动平均所得的均值和方差\n",
    "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2:\n",
    "            # 使用全连接层的情况，计算特征维上的均值和方差\n",
    "            mean = X.mean(dim=0)\n",
    "            var = ((X - mean) ** 2).mean(dim=0)\n",
    "        else:\n",
    "            # 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差。\n",
    "            # 这里我们需要保持X的形状以便后面可以做广播运算\n",
    "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
    "            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
    "        # 训练模式下，用当前的均值和方差做标准化\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        # 更新移动平均的均值和方差\n",
    "        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean\n",
    "        moving_var = momentum * moving_var + (1.0 - momentum) * var\n",
    "    Y = gamma * X_hat + beta  # 缩放和移位\n",
    "    return Y, moving_mean.data, moving_var.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724761fe-b2f9-48e4-8839-fb9829048126",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    # num_features：完全连接层的输出数量或卷积层的输出通道数。\n",
    "    # num_dims：2表示完全连接层，4表示卷积层\n",
    "    def __init__(self, num_features, num_dims):\n",
    "        super().__init__()\n",
    "        if num_dims == 2:\n",
    "            shape = (1, num_features)\n",
    "        else:\n",
    "            shape = (1, num_features, 1, 1)\n",
    "        # 参与求梯度和迭代的拉伸和偏移参数，分别初始化成1和0\n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "        # 非模型参数的变量初始化为0和1\n",
    "        self.moving_mean = torch.zeros(shape)\n",
    "        self.moving_var = torch.ones(shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 如果X不在内存上，将moving_mean和moving_var\n",
    "        # 复制到X所在显存上\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.to(X.device)\n",
    "        # 保存更新过的moving_mean和moving_var\n",
    "        Y, self.moving_mean, self.moving_var = batch_norm(\n",
    "            X, self.gamma, self.beta, self.moving_mean,\n",
    "            self.moving_var, eps=1e-5, momentum=0.9)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212a59db-48c8-4070-b1d3-f0c755409729",
   "metadata": {},
   "source": [
    "### 使用批量规范化层的 LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d328353-835e-4e0f-b307-ad46edb4e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5), BatchNorm(6, num_dims=4), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), BatchNorm(16, num_dims=4), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),\n",
    "    nn.Linear(16*4*4, 120), BatchNorm(120, num_dims=2), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), BatchNorm(84, num_dims=2), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee56175-630e-40a8-98ef-484a08de751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size = 1.0, 10, 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff170e5-864f-4994-825d-2aa5a22f9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看从第一个批量规范化层中学到的拉伸参数gamma和偏移参数beta。\n",
    "net[1].gamma.reshape((-1,)), net[1].beta.reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2902e97-eab6-495c-b775-edddc3313690",
   "metadata": {},
   "source": [
    "### 使用框架里面的批量规范化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e323cf-25bb-462f-bcb8-0667abc6768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5), nn.BatchNorm2d(6), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.BatchNorm2d(16), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),\n",
    "    nn.Linear(256, 120), nn.BatchNorm1d(120), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), nn.BatchNorm1d(84), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcddc5f-acb8-4599-9bf6-faaaff93b6b3",
   "metadata": {},
   "source": [
    "#### 小结\n",
    "\n",
    "* 在模型训练过程中，批量规范化利用小批量的均值和标准差，不断调整神经网络的中间输出，使整个神经网络各层的中间输出值更加稳定。\n",
    "* 批量规范化在全连接层和卷积层的使用略有不同。\n",
    "* 批量规范化层和暂退层一样，在训练模式和预测模式下计算不同。\n",
    "* 批量归一化固定小批量中的均值和方差，然后学习出适合的偏移和缩放\n",
    "* 可以加速收敛速度，但一般不改变模型精度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4841779-eb43-49db-bc70-02fa1bb11a44",
   "metadata": {},
   "source": [
    "## 残差网络（ResNet）\n",
    "对于非嵌套函数类，较复杂（由较大区域表示）的函数类不能保证更接近“真”函数（ $f^*$ ）。这种现象在嵌套函数类中不会发生。\n",
    "\n",
    "![对于非嵌套函数类，较复杂（由较大区域表示）的函数类不能保证更接近“真”函数（ $f^*$ ）。这种现象在嵌套函数类中不会发生。](../image/functionclasses.svg)\n",
    "\n",
    "背景：\n",
    "- ResNet由微软亚洲研究院的何凯明等人于2015年提出，是CNN图像史上的一件里程碑事件。\n",
    "- 其提出背景是解决深度神经网络在增加层数时遇到的梯度消失和表示瓶颈问题。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9c404b-3d99-4817-8605-28e15f847ed8",
   "metadata": {},
   "source": [
    "### 残差块\n",
    "\n",
    "- ResNet的核心思想是通过引入残差连接（residual connections）来解决深层网络训练过程中的问题。\n",
    "- 残差连接具体是通过“跳跃连接”（skip connection）实现的，即将输入信号直接添加到输出上，绕过一些层，使梯度在反向传播过程中能更好地流动。\n",
    "- 这种设计使得网络可以学习到残差（即输入与输出的差），而不是全局特征，从而更容易训练深层网络。\n",
    "\n",
    "![一个正常块（左图）和一个残差块（右图）。](../image/residual-block.svg)\n",
    "\n",
    "ResNet将函数展开为:$f(\\mathbf{x}) = \\mathbf{x} + g(\\mathbf{x})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd617f1-b838-4db5-8697-1f8f4b07907d",
   "metadata": {},
   "source": [
    "ResNet沿用了VGG完整的$3\\times 3$卷积层设计。\n",
    "残差块里首先有2个有相同输出通道数的$3\\times 3$卷积层。\n",
    "每个卷积层后接一个批量规范化层和ReLU激活函数。\n",
    "然后我们通过跨层数据通路，跳过这2个卷积运算，将输入直接加在最后的ReLU激活函数前。\n",
    "这样的设计要求2个卷积层的输出与输入形状一样，从而使它们可以相加。\n",
    "如果想改变通道数，就需要引入一个额外的$1\\times 1$卷积层来将输入变换成需要的形状后再做相加运算。\n",
    "\n",
    "![包含以及不包含 $1 \\times 1$ 卷积层的残差块。](../image/resnet-block.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb82467c-2d01-4b3e-a509-f738f43addfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 残差块的实现如下：\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "\n",
    "#  一种是当use_1x1conv=False时，应用ReLU非线性函数之前，将输入添加到输出。 \n",
    "# 另一种是当use_1x1conv=True时，添加通过1X1卷积调整通道和分辨率。\n",
    "class Residual(nn.Module):  #@save\n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
    "                               kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
    "                               kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
    "                                   kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b5e51b6-c2c8-45cc-96ae-9c3902fe2638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 6, 6])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Residual(3,3)\n",
    "X = torch.rand(4, 3, 6, 6)\n",
    "Y = blk(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d4a006a-f25c-4cbb-b6d5-20a9787afd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 3, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Residual(3,6, use_1x1conv=True, strides=2)\n",
    "blk(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f7998c-58f5-458f-bf69-0f8b2cd04961",
   "metadata": {},
   "source": [
    "不同类型的残差块\n",
    "![不同类型的残差块](../image/residual_block_other.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5581ec24-c7ea-40ab-9db4-0fc461d10ad3",
   "metadata": {},
   "source": [
    "### ResNet模型\n",
    "\n",
    "ResNet的前两层跟之前介绍的GoogLeNet中的一样：\n",
    "在输出通道数为64、步幅为2的$7 \\times 7$卷积层后，接步幅为2的$3 \\times 3$的最大汇聚层。\n",
    "不同之处在于ResNet每个卷积层后增加了批量规范化层。\n",
    "\n",
    "每个模块有4个卷积层（不包括恒等映射的$1\\times 1$卷积层）。\n",
    "加上第一个$7\\times 7$卷积层和最后一个全连接层，共有18层。\n",
    "因此，这种模型通常被称为ResNet-18。\n",
    "\n",
    "![ResNet-18 架构](../image/resnet18.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "136f314f-56b7-4504-abd8-1b7f01257ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ResNet-18 实现\n",
    "def resnet_block(input_channels, num_channels, num_residuals,\n",
    "                 first_block=False):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(input_channels, num_channels,\n",
    "                                use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels, num_channels))\n",
    "    return blk\n",
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))\n",
    "b3 = nn.Sequential(*resnet_block(64, 128, 2))\n",
    "b4 = nn.Sequential(*resnet_block(128, 256, 2))\n",
    "b5 = nn.Sequential(*resnet_block(256, 512, 2))\n",
    "# 与GoogLeNet一样，在ResNet中加入全局平均汇聚层，以及全连接层输出\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5,\n",
    "                    nn.AdaptiveAvgPool2d((1,1)),\n",
    "                    nn.Flatten(), nn.Linear(512, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cebb4eab-a9d6-422f-94ec-641e38810ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 192, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 480, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 832, 7, 7])\n",
      "Sequential output shape:\t torch.Size([1, 1024])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1, 224, 224))\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfaeb98-4ed3-4975-bff9-0a117c2b444f",
   "metadata": {},
   "source": [
    "### 训练模型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aab234-a1a6-4732-88f4-2d505f427e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size = 0.05, 10, 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00a363b-a918-4e27-a4ae-54bec68fa070",
   "metadata": {},
   "source": [
    "## 稠密连接网络（DenseNet）\n",
    "\n",
    "ResNet极大地改变了如何参数化深层网络中函数的观点。 稠密连接网络（DenseNet）在某种程度上是ResNet的逻辑扩展。\n",
    "\n",
    "ResNet将$f$分解为两部分：一个简单的线性项和一个复杂的非线性项。\n",
    "\n",
    "![ResNet（左）与 DenseNet（右）在跨层连接上的主要区别：使用相加和使用连结。](../image/densenet-block.svg)\n",
    "\n",
    "ResNet和DenseNet的关键区别在于，DenseNet输出是连接而不是如ResNet的简单相加。\n",
    "\n",
    "稠密网络主要由2部分构成：稠密块（dense block）和过渡层（transition layer）。 前者定义如何连接输入和输出，而后者则控制通道数量，使其不会太复杂。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078ce4e5-d480-4164-bfb2-7f3245f27053",
   "metadata": {},
   "source": [
    "### 稠密块体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "415ba910-712e-471d-90e7-bfcf6c509ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "def conv_block(input_channels, num_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(input_channels), nn.ReLU(),\n",
    "        nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7eb5af7-e551-45ad-ae96-e153e5da6be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    # 稠密块由多个卷积块组成，每个卷积块使用相同数量的输出通道。 \n",
    "    def __init__(self, num_convs, input_channels, num_channels):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        layer = []\n",
    "        for i in range(num_convs):\n",
    "            layer.append(conv_block(\n",
    "                num_channels * i + input_channels, num_channels))\n",
    "        self.net = nn.Sequential(*layer)\n",
    "# 在前向传播中，我们将每个卷积块的输入和输出在通道维上连结。\n",
    "    def forward(self, X):\n",
    "        for blk in self.net:\n",
    "            Y = blk(X)\n",
    "            # 连接通道维度上每个块的输入和输出\n",
    "            X = torch.cat((X, Y), dim=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e39f744-ef12-4e70-a7c6-e6586a16117b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 23, 8, 8])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = DenseBlock(2, 3, 10)\n",
    "X = torch.randn(4, 3, 8, 8)\n",
    "Y = blk(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688b612f-24c2-4ce4-b51b-477420516478",
   "metadata": {},
   "source": [
    "### 过渡层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "758183f0-81ad-42c3-9996-77fa7bf3c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_block(input_channels, num_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(input_channels), nn.ReLU(),\n",
    "        nn.Conv2d(input_channels, num_channels, kernel_size=1),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9b5c828-b1c1-418a-b58c-d361a5b73e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 4, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = transition_block(23, 10)\n",
    "blk(Y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95001959-9edf-44f9-8779-e5d22942950c",
   "metadata": {},
   "source": [
    "### DenseNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3662c1d1-573b-4b6c-a03e-785efe09f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(\n",
    "    nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "    nn.BatchNorm2d(64), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "# num_channels为当前的通道数\n",
    "num_channels, growth_rate = 64, 32\n",
    "num_convs_in_dense_blocks = [4, 4, 4, 4]\n",
    "blks = []\n",
    "for i, num_convs in enumerate(num_convs_in_dense_blocks):\n",
    "    blks.append(DenseBlock(num_convs, num_channels, growth_rate))\n",
    "    # 上一个稠密块的输出通道数\n",
    "    num_channels += num_convs * growth_rate\n",
    "    # 在稠密块之间添加一个转换层，使通道数量减半\n",
    "    if i != len(num_convs_in_dense_blocks) - 1:\n",
    "        blks.append(transition_block(num_channels, num_channels // 2))\n",
    "        num_channels = num_channels // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d7dc3-bc1b-4bed-9bd5-244bca5c200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    b1, *blks,\n",
    "    nn.BatchNorm2d(num_channels), nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(num_channels, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d19220c-d18a-425f-970b-561e788eebe3",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611ae39-2c3b-4a9f-8d8c-2b98fec6fd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size = 0.1, 10, 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
