{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMl+yHCKak6jUyO6/JKSQ3p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d42b44fc3c53422eaf0f4ed80c2e91bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa7a4267b15242ff8a49f6cd0a6f0326",
              "IPY_MODEL_736a9cf6527d48a9b6de281b4c729b02",
              "IPY_MODEL_e4ff0cc8b3804801bd1bd0e49eee0350"
            ],
            "layout": "IPY_MODEL_2dd6ec8fdb9842b4b0ef14b426a2b846"
          }
        },
        "aa7a4267b15242ff8a49f6cd0a6f0326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3705e3e3354345dfbe10f97103ef16ac",
            "placeholder": "​",
            "style": "IPY_MODEL_8291d8b3a97541fda216d71bbba34109",
            "value": "Map: 100%"
          }
        },
        "736a9cf6527d48a9b6de281b4c729b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13aeb064818542b1a63beccb57bac59a",
            "max": 189155,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1cab43969da9406980cde0d3fbb797a8",
            "value": 189155
          }
        },
        "e4ff0cc8b3804801bd1bd0e49eee0350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e93366669a549479c175e6c0e1dbfe7",
            "placeholder": "​",
            "style": "IPY_MODEL_eb502c95194d445c9a7758c3ea2339ae",
            "value": " 189155/189155 [00:29&lt;00:00, 7132.69 examples/s]"
          }
        },
        "2dd6ec8fdb9842b4b0ef14b426a2b846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3705e3e3354345dfbe10f97103ef16ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8291d8b3a97541fda216d71bbba34109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13aeb064818542b1a63beccb57bac59a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cab43969da9406980cde0d3fbb797a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e93366669a549479c175e6c0e1dbfe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb502c95194d445c9a7758c3ea2339ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a46c79c256684fb68537cf392dc66c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_749a662b596d4a8fa1ae56aa96f9c33a",
              "IPY_MODEL_0ce635baf2494a868f96317c2e9e49bf",
              "IPY_MODEL_95b47253e9ba4b7ca4a75d79077c9cd1"
            ],
            "layout": "IPY_MODEL_2f18c67805f944da9887c8dcf8747b9b"
          }
        },
        "749a662b596d4a8fa1ae56aa96f9c33a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83c148c3e67f4366a96daaa85c18abde",
            "placeholder": "​",
            "style": "IPY_MODEL_25a6964ed62046899e2ddac2a49162b8",
            "value": "Map: 100%"
          }
        },
        "0ce635baf2494a868f96317c2e9e49bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db519e8e179b4d54b26c69373e011b8d",
            "max": 21018,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff55b99bb40b4b6794726fc9f5ac2950",
            "value": 21018
          }
        },
        "95b47253e9ba4b7ca4a75d79077c9cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0bb246190c24b08ae74bf3b6c173e71",
            "placeholder": "​",
            "style": "IPY_MODEL_090acffb37104ee986b85d96c486642d",
            "value": " 21018/21018 [00:03&lt;00:00, 5377.31 examples/s]"
          }
        },
        "2f18c67805f944da9887c8dcf8747b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83c148c3e67f4366a96daaa85c18abde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25a6964ed62046899e2ddac2a49162b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db519e8e179b4d54b26c69373e011b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff55b99bb40b4b6794726fc9f5ac2950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0bb246190c24b08ae74bf3b6c173e71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "090acffb37104ee986b85d96c486642d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a008cd52bd1344258a70a9bc568940a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02956cd946904ff48e8120cd101a225b",
              "IPY_MODEL_871c1e5bfe6942bca391554b29daac1e",
              "IPY_MODEL_e95502f06e25406caf9067b02efa4f25"
            ],
            "layout": "IPY_MODEL_d167e7406bd948f39af1da22d4dba84d"
          }
        },
        "02956cd946904ff48e8120cd101a225b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8fef690d0ef48c08dab664aeca24f3e",
            "placeholder": "​",
            "style": "IPY_MODEL_3709ecfa11384ecb8b27260fd98ac2d8",
            "value": "Downloading builder script: 100%"
          }
        },
        "871c1e5bfe6942bca391554b29daac1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38f594e3d6344388a2250dfb4716004c",
            "max": 8146,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb53e92f5f7e4709a4dfee4b5fc20623",
            "value": 8146
          }
        },
        "e95502f06e25406caf9067b02efa4f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f49f81cd42c34c8c8a1cd8a3ef29510c",
            "placeholder": "​",
            "style": "IPY_MODEL_c516664a408242d893b44a737f54691e",
            "value": " 8.15k/8.15k [00:00&lt;00:00, 389kB/s]"
          }
        },
        "d167e7406bd948f39af1da22d4dba84d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8fef690d0ef48c08dab664aeca24f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3709ecfa11384ecb8b27260fd98ac2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38f594e3d6344388a2250dfb4716004c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb53e92f5f7e4709a4dfee4b5fc20623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f49f81cd42c34c8c8a1cd8a3ef29510c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c516664a408242d893b44a737f54691e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leoli04/llms-notebooks/blob/main/huggingface/hf_nlp_07_main_NLP_tasks_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 主要的NLP任务(二)"
      ],
      "metadata": {
        "id": "46rdsS956UyP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0DrhH-0s71_"
      },
      "source": [
        "### 翻译\n",
        "\n",
        "这是另一个序列到序列的任务，这意味着它是一个可以表述为从一个序列到另一个序列的问题。从这个意义上说，这个问题非常接近总结，您可以将我们在这里看到的内容应用于其他序列到序列的问题，例如：\n",
        "\n",
        "- 风格迁移：创建一个模型，将某种风格的文本翻译成另一种风格（例如，正式英语翻译成休闲英语，或者莎士比亚英语翻译成现代英语）\n",
        "\n",
        "- 生成式问答：创建一个模型，根据给定的上下文生成问题的答案"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZtux2bntYxV"
      },
      "source": [
        "在本节中，我们将在 KDE4 数据集（KDE 应用程序的本地化文件数据集）上微调预训练的 Marian 模型，以将其从英语翻译为法语（因为许多 Hugging Face 员工都说这两种语言）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrpNsmkH-x9h"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!pip install accelerate\n",
        "# To run the training on TPU, you will need to uncomment the following line:\n",
        "# !pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "!apt install git-lfs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch] -U"
      ],
      "metadata": {
        "id": "PMO_jqfu6ISB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 准备数据\n",
        "\n",
        "我们将在本节中使用 KDE4 数据集，但只要您有要翻译的两种语言的句子对，您就可以轻松地调整代码以使用您自己的数据。"
      ],
      "metadata": {
        "id": "aj4hcUMu6NgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### KDE4 数据集"
      ],
      "metadata": {
        "id": "TOiuxs2-6qgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "# 下载数据集\n",
        "raw_datasets = load_dataset(\"kde4\", lang1=\"en\", lang2=\"fr\")\n",
        "\n",
        "# 查看数据集结构\n",
        "raw_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z48vDtv6to8",
        "outputId": "23bea01a-90d9-48c3-edaa-0b1e3fed0b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1486: FutureWarning: The repository for kde4 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/kde4\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'translation'],\n",
              "        num_rows: 210173\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用训练数据的10%作为test\n",
        "split_datasets = raw_datasets[\"train\"].train_test_split(train_size=0.9, seed=20)\n",
        "split_datasets\n",
        "# 将 \"test\" 重命名为 \"validation\"\n",
        "split_datasets[\"validation\"] = split_datasets.pop(\"test\")"
      ],
      "metadata": {
        "id": "MvLgSeQn8SHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_checkpoint = \"Helsinki-NLP/opus-mt-en-fr\"\n",
        "translator = pipeline(\"translation\", model=model_checkpoint)\n",
        "translator(\"Default to expanded threads\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dMHs2FM9HMD",
        "outputId": "2fe5b57a-4318-49e9-8f82-320c589162e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'Par défaut pour les threads élargis'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "法国工程师在交谈时将大多数计算机科学专用单词保留为英语。例如，“threads”一词很可能出现在法语句子中，尤其是在技术对话中；但在这个数据集中，它已被翻译成更正确的“fils de Discussion”。还有“plugin”，它并不是正式的法语单词，但大多数母语人士都会理解它，而无需费心翻译。在 KDE4 数据集中，这个词已被翻译成法语，成为更官方的“module d’extension”"
      ],
      "metadata": {
        "id": "zyX-SoDH9ZYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_datasets[\"train\"][172][\"translation\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDeK21-N9qZ5",
        "outputId": "011b3c59-f3a4-45a7-f5b6-08b328a89b17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': 'Unable to import %1 using the OFX importer plugin. This file is not the correct format.',\n",
              " 'fr': \"Impossible d'importer %1 en utilisant le module d'extension d'importation OFX. Ce fichier n'a pas un format correct.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "然而，我们的预训练模型坚持使用紧凑且熟悉的英语单词："
      ],
      "metadata": {
        "id": "7-WGQPZ89w4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator(\n",
        "    \"Unable to import %1 using the OFX importer plugin. This file is not the correct format.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rg7w14cc98Uf",
        "outputId": "f72e68ad-5738-466b-de50-8ec4ffc11afd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': \"Impossible d'importer %1 en utilisant le plugin d'importateur OFX. Ce fichier n'est pas le bon format.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 处理数据\n",
        "\n",
        "我们数据的准备非常简单。只有一件事要记住；您需要确保分词器以输出语言（此处为法语）处理目标。您可以通过将目标传递给分词器的 __call__ 方法的 text_targets 参数来完成此操作。"
      ],
      "metadata": {
        "id": "fFVoixpz-HBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 创建 tokenizer 对象"
      ],
      "metadata": {
        "id": "GLH2r7AR-6VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"Helsinki-NLP/opus-mt-en-fr\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "e-Bn-VCL-86r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_sentence = split_datasets[\"train\"][1][\"translation\"][\"en\"]\n",
        "fr_sentence = split_datasets[\"train\"][1][\"translation\"][\"fr\"]\n",
        "\n",
        "inputs = tokenizer(en_sentence, text_target=fr_sentence)\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQpQ0f9We8go",
        "outputId": "a4034368-3a3f-4c3e-c05b-19221f315ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [47591, 12, 9842, 19634, 9, 0], 'attention_mask': [1, 1, 1, 1, 1, 1], 'labels': [577, 5891, 2, 3184, 16, 2542, 5, 1710, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 定义数据预处理函数"
      ],
      "metadata": {
        "id": "LrLWwuLMBHpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 128\n",
        "\n",
        "# 数据集的预处理函数\n",
        "def preprocess_function(examples):\n",
        "    inputs = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
        "    targets = [ex[\"fr\"] for ex in examples[\"translation\"]]\n",
        "    model_inputs = tokenizer(\n",
        "        inputs, text_target=targets, max_length=max_length, truncation=True\n",
        "    )\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "i776YdiuAJCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ⚠️ 我们不关注目标的注意力掩模，因为模型不会期望它。相反，与填充标记相对应的标签应设置为 -100 ，以便在损失计算中忽略它们。这将由我们的数据整理器稍后完成，因为我们正在应用动态填充"
      ],
      "metadata": {
        "id": "W1IZjBq4AtAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 数据预处理"
      ],
      "metadata": {
        "id": "uzleCSUaBLAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 数据预处理\n",
        "tokenized_datasets = split_datasets.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=split_datasets[\"train\"].column_names,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "d42b44fc3c53422eaf0f4ed80c2e91bc",
            "aa7a4267b15242ff8a49f6cd0a6f0326",
            "736a9cf6527d48a9b6de281b4c729b02",
            "e4ff0cc8b3804801bd1bd0e49eee0350",
            "2dd6ec8fdb9842b4b0ef14b426a2b846",
            "3705e3e3354345dfbe10f97103ef16ac",
            "8291d8b3a97541fda216d71bbba34109",
            "13aeb064818542b1a63beccb57bac59a",
            "1cab43969da9406980cde0d3fbb797a8",
            "8e93366669a549479c175e6c0e1dbfe7",
            "eb502c95194d445c9a7758c3ea2339ae",
            "a46c79c256684fb68537cf392dc66c4e",
            "749a662b596d4a8fa1ae56aa96f9c33a",
            "0ce635baf2494a868f96317c2e9e49bf",
            "95b47253e9ba4b7ca4a75d79077c9cd1",
            "2f18c67805f944da9887c8dcf8747b9b",
            "83c148c3e67f4366a96daaa85c18abde",
            "25a6964ed62046899e2ddac2a49162b8",
            "db519e8e179b4d54b26c69373e011b8d",
            "ff55b99bb40b4b6794726fc9f5ac2950",
            "f0bb246190c24b08ae74bf3b6c173e71",
            "090acffb37104ee986b85d96c486642d"
          ]
        },
        "id": "Ebfi_5QvA3Qx",
        "outputId": "402b49d7-9933-4aa9-b3d1-563332a04e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/189155 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d42b44fc3c53422eaf0f4ed80c2e91bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/21018 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a46c79c256684fb68537cf392dc66c4e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 使用 Trainer API 微调模型"
      ],
      "metadata": {
        "id": "uxnMX-O7BROz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们在这里使用 Seq2SeqTrainer ，它是 Trainer 的子类将使我们能够使用 generate() 方法根据输入预测输出来正确处理评估。"
      ],
      "metadata": {
        "id": "X6h8D_mSBZs1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 加载模型"
      ],
      "metadata": {
        "id": "kPx1nsIeBsts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "_5vi6P_WBhmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 数据整理"
      ],
      "metadata": {
        "id": "WiKNK5z7B3Rp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们需要一个数据整理器来处理动态批处理的填充。在这种情况下，我们不能像第 3 章那样只使用 DataCollatorWithPadding ，因为它只会填充输入（输入 ID、注意力掩码和令牌类型 ID）。我们的标签也应该填充到标签中遇到的最大长度。并且，用于填充标签的填充值应该是 -100 而不是标记器的填充标记，以确保在损失计算中忽略这些填充值。"
      ],
      "metadata": {
        "id": "C0xB8SoHCDL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们将使用DataCollatorForSeq2Seq 完成。它采用 tokenizer 用于预处理输入，也采用 model。这是因为该数据整理器还将负责准备解码器输入 ID，这些 ID 是开头带有特殊标记的标签的移位版本。由于这种转变对于不同的体系结构略有不同，因此 DataCollatorForSeq2Seq 需要知道 model 对象："
      ],
      "metadata": {
        "id": "TF0v9UNACOWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "# 稍后会将data_collator 传递给 Seq2SeqTrainer"
      ],
      "metadata": {
        "id": "VVZgGX_ZCkSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 验证上述说明\n",
        "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(1, 3)])\n",
        "batch.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqThpTmyCvC7",
        "outputId": "c011a09b-df6e-4f00-8125-5e72c96731f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch[\"labels\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIhRhzxXC4zf",
        "outputId": "ed823758-782a-4e67-8021-6cc8364db3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  577,  5891,     2,  3184,    16,  2542,     5,  1710,     0,  -100,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100],\n",
              "        [ 1211,     3,    49,  9409,  1211,     3, 29140,   817,  3124,   817,\n",
              "           550,  7032,  5821,  7907, 12649,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch[\"decoder_input_ids\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muB9gR7WDCja",
        "outputId": "868cfdde-918d-4676-bdfb-670b85543d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[59513,   577,  5891,     2,  3184,    16,  2542,     5,  1710,     0,\n",
              "         59513, 59513, 59513, 59513, 59513, 59513],\n",
              "        [59513,  1211,     3,    49,  9409,  1211,     3, 29140,   817,  3124,\n",
              "           817,   550,  7032,  5821,  7907, 12649]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 3):\n",
        "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G78iwbDODc00",
        "outputId": "ce3c9643-eaf7-4d3a-d142-b3c4494f90a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[577, 5891, 2, 3184, 16, 2542, 5, 1710, 0]\n",
            "[1211, 3, 49, 9409, 1211, 3, 29140, 817, 3124, 817, 550, 7032, 5821, 7907, 12649, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 指标"
      ],
      "metadata": {
        "id": "Cn-tbTeeDfpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "用于翻译的传统指标是 BLEU 分数，BLEU 分数评估翻译与其标签的接近程度。它不衡量模型生成输出的可理解性或语法正确性，而是使用统计规则来确保生成输出中的所有单词也出现在目标中。还有一些规则，如果相同单词在目标中没有重复，则会对其重复进行惩罚（以避免模型输出类似 \"the the the the the\" 的句子），并输出比目标中的句子短的句子。\n",
        "\n",
        "BLEU 的一个弱点是它期望文本已经被标记化，这使得比较使用不同标记器的模型之间的分数变得困难。因此，当今对翻译模型进行基准测试最常用的指标是 SacreBLEU，它通过标准化标记化步骤来解决这个弱点（以及其他弱点）。"
      ],
      "metadata": {
        "id": "AUra8bZADuJ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 安装&加载指标"
      ],
      "metadata": {
        "id": "sl2ZzKqIFBjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "UaazfnHMEPg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "# 加载评估指标\n",
        "metric = evaluate.load(\"sacrebleu\")\n",
        "# 分数可以从 0 到 100，越高越好。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a008cd52bd1344258a70a9bc568940a3",
            "02956cd946904ff48e8120cd101a225b",
            "871c1e5bfe6942bca391554b29daac1e",
            "e95502f06e25406caf9067b02efa4f25",
            "d167e7406bd948f39af1da22d4dba84d",
            "a8fef690d0ef48c08dab664aeca24f3e",
            "3709ecfa11384ecb8b27260fd98ac2d8",
            "38f594e3d6344388a2250dfb4716004c",
            "fb53e92f5f7e4709a4dfee4b5fc20623",
            "f49f81cd42c34c8c8a1cd8a3ef29510c",
            "c516664a408242d893b44a737f54691e"
          ]
        },
        "id": "MkTPX-4ZESFy",
        "outputId": "d7e1af44-b6f1-4742-b674-990be8218a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a008cd52bd1344258a70a9bc568940a3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 测试\n",
        "predictions = [\n",
        "    \"This plugin lets you translate web pages between several languages automatically.\"\n",
        "]\n",
        "references = [\n",
        "    [\n",
        "        \"This plugin allows you to automatically translate web pages between several languages.\"\n",
        "    ]\n",
        "]\n",
        "metric.compute(predictions=predictions, references=references)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdRofOCqEd5s",
        "outputId": "8ace7c82-3545-4a66-afcd-8853d0d5b8c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 46.750469682990165,\n",
              " 'counts': [11, 6, 4, 3],\n",
              " 'totals': [12, 11, 10, 9],\n",
              " 'precisions': [91.66666666666667,\n",
              "  54.54545454545455,\n",
              "  40.0,\n",
              "  33.333333333333336],\n",
              " 'bp': 0.9200444146293233,\n",
              " 'sys_len': 12,\n",
              " 'ref_len': 13}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 使用指标计算"
      ],
      "metadata": {
        "id": "Wn5FCA_yFHiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    # In case the model returns more than the prediction logits\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100s in the labels as we can't decode them\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    return {\"bleu\": result[\"score\"]}"
      ],
      "metadata": {
        "id": "XfvAKgZ1FKQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 微调模型"
      ],
      "metadata": {
        "id": "XHanzu8zFmMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 构建微调参数"
      ],
      "metadata": {
        "id": "fpICWP1dFrLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"marian-finetuned-kde4-en-to-fr\",\n",
        "    evaluation_strategy=\"no\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=3,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTal9qCeFqVF",
        "outputId": "2b45ebcb-adcc-4e68-b090-83b0b1ef6585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- f\"marian-finetuned-kde4-en-to-fr\" 模型输出目录\n",
        "- evaluation_strategy=\"no\": 指定评估策略。这里设置为\"no\"意味着在训练过程中不进行评估。\n",
        "- save_strategy=\"epoch\": 指定何时保存模型。这里设置为\"epoch\"，意味着在每个训练周期结束时保存模型。\n",
        "- learning_rate=2e-5: 设置模型训练时的学习率。学习率是优化算法在参数空间中步进的大小。\n",
        "- per_device_train_batch_size=32: 每个设备（GPU/CPU）在训练时的批量大小。批量大小是指每次模型更新前用于计算梯度的样本数量。\n",
        "- per_device_eval_batch_size=64: 每个设备（GPU/CPU）在评估时的批量大小。这个参数在evaluation_strategy=\"no\"时不会用到。\n",
        "- weight_decay=0.01: 设置权重衰减（L2正则化）的强度，用于防止模型过拟合。\n",
        "- save_total_limit=3:限制训练过程中保存的模型总数。这里设置为3，意味着最多只保存3个模型。\n",
        "- num_train_epochs=3: 设置训练周期的数量。一个训练周期意味着整个训练数据集被完整地遍历一次。\n",
        "- fp16=True ，是否使用混合精度（16位浮点数）训练。这可以加速训练并减少内存使用，同时保持几乎相同的模型精度。\n",
        "- predict_with_generate=True 当设置为True时，使用模型的generate方法进行预测，这通常用于生成文本。\n",
        "- push_to_hub=True 在每个 epoch 结束时将模型上传到 Hub"
      ],
      "metadata": {
        "id": "t3CRNbCSF4dk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 构建训练器"
      ],
      "metadata": {
        "id": "WEeAk7uJGcFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "S2PG6vkXGSaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 查看模型获得的分数\n",
        "\n",
        "我们将首先查看模型获得的分数，以仔细检查我们的微调是否不会让事情变得更糟。"
      ],
      "metadata": {
        "id": "QNMGru1YGnmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(max_length=max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "PKR9o7IlGj09",
        "outputId": "80ebdc47-0148-4673-da89-5150fceebe5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='184' max='329' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [184/329 12:21 < 09:47, 0.25 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='329' max='329' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [329/329 22:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 1.6966999769210815,\n",
              " 'eval_bleu': 39.264985846713074,\n",
              " 'eval_runtime': 1480.1431,\n",
              " 'eval_samples_per_second': 14.2,\n",
              " 'eval_steps_per_second': 0.222}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 训练模型"
      ],
      "metadata": {
        "id": "Eg-fGyv_Gv56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NnxLV6SyGuye",
        "outputId": "c42d6568-d1ea-4e8e-8b58-73f161fab736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17736' max='17736' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [17736/17736 1:06:57, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.386400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.230700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.195500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.137700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.111000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.079100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.044200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.032000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.039100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.997000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.966900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.887600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.918400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.906200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.896600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.891100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.890100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.885400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.875500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.894500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.870300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.879700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.852400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.807100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.805100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.825300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.815600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.815500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.809700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.830500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.813600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>0.807900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.818000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>0.813400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59513]], 'forced_eos_token_id': 0}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59513]], 'forced_eos_token_id': 0}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59513]], 'forced_eos_token_id': 0}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=17736, training_loss=0.9368231966520248, metrics={'train_runtime': 4019.1469, 'train_samples_per_second': 141.19, 'train_steps_per_second': 4.413, 'total_flos': 1.1353213104095232e+16, 'train_loss': 0.9368231966520248, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 再次查看模型得分"
      ],
      "metadata": {
        "id": "ihnm9V0YG1_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(max_length=max_length)"
      ],
      "metadata": {
        "id": "zCCYxJWUG3b6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 上传模型"
      ],
      "metadata": {
        "id": "TBQpM1yjHF76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(tags=\"translation\", commit_message=\"Training complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "KdZp6c2BHFJd",
        "outputId": "19170d1f-4f0a-4e89-fd06-08e045fd54e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59513]], 'forced_eos_token_id': 0}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/leoli04/marian-finetuned-kde4-en-to-fr/commit/f727d3df8d659fe7c2a8db98a54ea1abc22d1b0b', commit_message='Training complete', commit_description='', oid='f727d3df8d659fe7c2a8db98a54ea1abc22d1b0b', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 自定义训练循环"
      ],
      "metadata": {
        "id": "jn6GbEZJHO_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 准备好训练用数据"
      ],
      "metadata": {
        "id": "-EZLolp2IOSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 构建训练数据集和验证数据集\n",
        "从数据集构建 DataLoader ，将数据集设置为 \"torch\" 格式"
      ],
      "metadata": {
        "id": "7aRCQ-NbHnuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"],\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=8,\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=8\n",
        ")"
      ],
      "metadata": {
        "id": "EB6dWzziHey_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 重新实例化模型"
      ],
      "metadata": {
        "id": "fQRvFoUsH9f5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n"
      ],
      "metadata": {
        "id": "gWMI-FLvHyEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 构建优化器"
      ],
      "metadata": {
        "id": "XJFj1P_mIJP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "MbXxPgrIIIgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 将上述对象传给accelerator.prepare\n",
        "\n",
        "> 如果您想在 Colab 笔记本中的 TPU 上进行训练，则需要将所有这些代码移至训练函数中，并且不应执行任何实例化 Accelerator 的单元。"
      ],
      "metadata": {
        "id": "N3kgnZtBIvF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator\n",
        "\n",
        "accelerator = Accelerator()\n",
        "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
        "    model, optimizer, train_dataloader, eval_dataloader\n",
        ")"
      ],
      "metadata": {
        "id": "-Nm-JswZIge8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 计算训练步骤数\n",
        "\n",
        "我们应该始终在准备数据加载器之后执行此操作，因为该方法将更改 DataLoader 的长度。"
      ],
      "metadata": {
        "id": "bwk4QkAZJQlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "num_train_epochs = 3\n",
        "num_update_steps_per_epoch = len(train_dataloader)\n",
        "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")"
      ],
      "metadata": {
        "id": "OBUF982UJNX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 将模型推送到仓库"
      ],
      "metadata": {
        "id": "oUvydHyAJl_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import Repository, get_full_repo_name\n",
        "\n",
        "model_name = \"marian-finetuned-kde4-en-to-fr-accelerate\"\n",
        "repo_name = get_full_repo_name(model_name)\n",
        "repo_name"
      ],
      "metadata": {
        "id": "h7vRwwXAJgzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"marian-finetuned-kde4-en-to-fr-accelerate\"\n",
        "repo = Repository(output_dir, clone_from=repo_name)"
      ],
      "metadata": {
        "id": "Rl4IgWi_JtKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 循环训练\n",
        "\n",
        "为了简化其评估部分，我们定义了这个 postprocess() 函数，它接受预测和标签并将它们转换为我们的 metric 对象期望的字符串列表"
      ],
      "metadata": {
        "id": "hoRWCBoOJyfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess(predictions, labels):\n",
        "    predictions = predictions.cpu().numpy()\n",
        "    labels = labels.cpu().numpy()\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
        "    return decoded_preds, decoded_labels"
      ],
      "metadata": {
        "id": "MNTOLyEnJ6EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "for epoch in range(num_train_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    for batch in train_dataloader:\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        accelerator.backward(loss)\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    for batch in tqdm(eval_dataloader):\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = accelerator.unwrap_model(model).generate(\n",
        "                batch[\"input_ids\"],\n",
        "                attention_mask=batch[\"attention_mask\"],\n",
        "                max_length=128,\n",
        "            )\n",
        "        labels = batch[\"labels\"]\n",
        "\n",
        "        # Necessary to pad predictions and labels for being gathered\n",
        "        generated_tokens = accelerator.pad_across_processes(\n",
        "            generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
        "        )\n",
        "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
        "\n",
        "        predictions_gathered = accelerator.gather(generated_tokens)\n",
        "        labels_gathered = accelerator.gather(labels)\n",
        "\n",
        "        decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)\n",
        "        metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "    results = metric.compute()\n",
        "    print(f\"epoch {epoch}, BLEU score: {results['score']:.2f}\")\n",
        "\n",
        "    # Save and upload\n",
        "    accelerator.wait_for_everyone()\n",
        "    unwrapped_model = accelerator.unwrap_model(model)\n",
        "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
        "    if accelerator.is_main_process:\n",
        "        tokenizer.save_pretrained(output_dir)\n",
        "        repo.push_to_hub(\n",
        "            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
        "        )"
      ],
      "metadata": {
        "id": "-QE3M3DsKL7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 使用模型"
      ],
      "metadata": {
        "id": "Dan3k_W6Kh2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Replace this with your own checkpoint\n",
        "model_checkpoint = \"huggingface-course/marian-finetuned-kde4-en-to-fr\"\n",
        "translator = pipeline(\"translation\", model=model_checkpoint)\n",
        "translator(\"Default to expanded threads\")"
      ],
      "metadata": {
        "id": "-9RXSd8jKmrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator(\n",
        "    \"Unable to import %1 using the OFX importer plugin. This file is not the correct format.\"\n",
        ")"
      ],
      "metadata": {
        "id": "mFhpY4SIKs2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 文本摘要\n",
        "\n",
        "在本节中，我们将了解如何使用 Transformer 模型将长文档压缩为摘要，这一任务称为文本摘要。这是最具挑战性的 NLP 任务之一，因为它需要一系列能力，例如理解长段落并生成捕获文档中主要主题的连贯文本。\n",
        "\n",
        "我们将训练英语和西班牙语的双语模型。在本节结束时，您将拥有一个可以总结客户评论的模型。"
      ],
      "metadata": {
        "id": "ll41cM7ZMKod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!pip install accelerate\n",
        "# To run the training on TPU, you will need to uncomment the following line:\n",
        "# !pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "!apt install git-lfs"
      ],
      "metadata": {
        "id": "PRyWC3yBBNZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch] -U"
      ],
      "metadata": {
        "id": "ye24Rd9RBSPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 准备多语言语料库\n",
        "\n",
        "我们将使用多语言亚马逊评论语料库来创建双语摘要器。该语料库由六种语言的亚马逊产品评论组成，通常用于对多语言分类器进行基准测试。然而，由于每条评论都附有一个简短的标题，因此我们可以使用标题作为我们的模型学习的目标摘要！"
      ],
      "metadata": {
        "id": "hp3e4pxgM5_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 下载数据集"
      ],
      "metadata": {
        "id": "KzoDfp0kNdnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "spanish_dataset = load_dataset(\"amazon_reviews_multi\", \"es\")\n",
        "english_dataset = load_dataset(\"amazon_reviews_multi\", \"en\")\n",
        "english_dataset"
      ],
      "metadata": {
        "id": "-sQ5i4diND4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 从训练集中抽取随机样本\n",
        "def show_samples(dataset, num_samples=3, seed=42):\n",
        "    sample = dataset[\"train\"].shuffle(seed=seed).select(range(num_samples))\n",
        "    for example in sample:\n",
        "        print(f\"\\n'>> Title: {example['review_title']}'\")\n",
        "        print(f\"'>> Review: {example['review_body']}'\")\n",
        "\n",
        "\n",
        "show_samples(english_dataset)"
      ],
      "metadata": {
        "id": "Ys_Yib0YNZXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "在单个 GPU 上训练所有 400,000 条评论的摘要模型会花费太长时间，因此我们将专注于为单个产品领域生成摘要。为了了解我们可以选择哪些域，让我们将 english_dataset 转换为 pandas.DataFrame 并计算每个产品类别的评论数量："
      ],
      "metadata": {
        "id": "5JlvU4ZFPeQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_dataset.set_format(\"pandas\")\n",
        "english_df = english_dataset[\"train\"][:]\n",
        "# Show counts for top 20 products\n",
        "english_df[\"product_category\"].value_counts()[:20]"
      ],
      "metadata": {
        "id": "w1iMHv7QPhOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "英语数据集中最受欢迎的产品是家居用品、服装和无线电子产品。不过，为了坚持亚马逊的主题，让我们集中精力总结书评——毕竟，这就是该公司的成立基础！我们可以看到两个符合要求的产品类别（ book 和 digital_ebook_purchase ），因此让我们仅针对这些产品过滤两种语言的数据集。"
      ],
      "metadata": {
        "id": "4eCfWKfiPv1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 数据过滤"
      ],
      "metadata": {
        "id": "x8XUQZ91Pz_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_books(example):\n",
        "    return (\n",
        "        example[\"product_category\"] == \"book\"\n",
        "        or example[\"product_category\"] == \"digital_ebook_purchase\"\n",
        "    )"
      ],
      "metadata": {
        "id": "GDaTMUIuPyre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_dataset.reset_format()"
      ],
      "metadata": {
        "id": "hGgmk7SZP90H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_books = spanish_dataset.filter(filter_books)\n",
        "english_books = english_dataset.filter(filter_books)\n",
        "show_samples(english_books)"
      ],
      "metadata": {
        "id": "kJRxvyStQAbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 将英语和西班牙语评论合并为单个 DatasetDict 对象\n",
        "\n",
        "🤗 Datasets 提供了一个方便的 concatenate_datasets() 函数（顾名思义），它将两个 Dataset 对象堆叠在一起。"
      ],
      "metadata": {
        "id": "_np6RJBuQOll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import concatenate_datasets, DatasetDict\n",
        "\n",
        "books_dataset = DatasetDict()\n",
        "\n",
        "for split in english_books.keys():\n",
        "  # 连接该分割的数据集\n",
        "    books_dataset[split] = concatenate_datasets(\n",
        "        [english_books[split], spanish_books[split]]\n",
        "    )\n",
        "    # 对结果进行洗牌，以确保我们的模型不会过度适合单一语言：\n",
        "    books_dataset[split] = books_dataset[split].shuffle(seed=42)\n",
        "\n",
        "# Peek at a few examples\n",
        "show_samples(books_dataset)"
      ],
      "metadata": {
        "id": "a69CfwwPQVn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 检查评论及其标题中的单词分布\n",
        "\n",
        "下图显示了单词分布，我们可以看到标题严重偏向于 1-2 个单词：\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/review-lengths.svg\"/>\n",
        "\n",
        "\n",
        "为了解决这个问题，我们将过滤掉标题非常短的示例，以便我们的模型可以生成更有趣的摘要。由于我们正在处理英语和西班牙语文本，因此我们可以使用粗略的启发式方法在空格上分割标题，然后使用我们可靠的 Dataset.filter() 方法."
      ],
      "metadata": {
        "id": "Zm7iXtwNRFgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books_dataset = books_dataset.filter(lambda x: len(x[\"review_title\"].split()) > 2)\n"
      ],
      "metadata": {
        "id": "_7LVddpDRkxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 文本摘要模型\n",
        "\n",
        "如果你仔细想想，文本摘要与机器翻译是类似的任务：我们有一个像评论这样的文本正文，我们希望将其“翻译”成更短的版本，以捕获输入的显着特征。因此，大多数用于摘要的 Transformer 模型都采用我们在第 1 章中首次遇到的编码器-解码器架构，尽管也有一些例外"
      ],
      "metadata": {
        "id": "dwK1EPnARpNP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "下表列出了一些流行的预训练模型，可以对其进行微调以进行汇总。\n",
        "\n",
        "| Transformer model                                          | Description                                                  | Multilingual? |\n",
        "| ---------------------------------------------------------- | ------------------------------------------------------------ | ------------- |\n",
        "| [GPT-2](https://huggingface.co/gpt2-xl)                    | 尽管训练为自回归语言模型，但您可以通过在输入文本末尾附加“TL;DR”来使 GPT-2 生成摘要。 | ❌             |\n",
        "| [PEGASUS](https://huggingface.co/google/pegasus-large)     | 使用预训练目标来预测多句子文本中的屏蔽句子。这个预训练目标比普通语言模型更接近总结，并且在流行的基准测试中得分很高。 | ❌             |\n",
        "| [T5](https://huggingface.co/t5-base)                       | 通用 Transformer 架构，在文本到文本框架中制定所有任务；例如，模型总结文档的输入格式是 `summarize: ARTICLE` 。 | ❌             |\n",
        "| [mT5](https://huggingface.co/google/mt5-base)              | T5的多语言版本，在多语言Common Crawl语料库（mC4）上进行预训练，涵盖101种语言。 | ✅             |\n",
        "| [BART](https://huggingface.co/facebook/bart-base)          | 一种新颖的 Transformer 架构，具有编码器和解码器堆栈，经过训练可以重建损坏的输入，结合了 BERT 和 GPT-2 的预训练方案。 | ❌             |\n",
        "| [mBART-50](https://huggingface.co/facebook/mbart-large-50) | BART 的多语言版本，经过 50 种语言的预训练。                  | ✅             |"
      ],
      "metadata": {
        "id": "QGT8rtFqR9DA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "正如您从该表中看到的，大多数用于摘要的 Transformer 模型（实际上是大多数 NLP 任务）都是单语言的。\n",
        "有一类多语言 Transformer 模型（例如 mT5 和 mBART）可以解决这个问题。这些模型是使用语言建模进行预训练的，但有一点不同：它们不是在一种语言的语料库上进行训练，而是同时对 50 多种语言的文本进行联合训练！"
      ],
      "metadata": {
        "id": "UBphsWDgS1L6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们将重点关注 mT5，这是一种基于 T5 的有趣架构，已在文本到文本框架中进行了预训练。在 T5 中，每个 NLP 任务都是根据提示前缀（如 summarize: ）来制定的，该前缀使模型适应生成的文本以适应提示。如下图所示，这使得 T5 非常通用，因为您可以用单个模型解决许多任务！\n",
        "\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/t5.svg\"/>"
      ],
      "metadata": {
        "id": "hJM7iIXbTTQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 预处理数据\n",
        "\n",
        "我们的下一个任务是对我们的评论及其标题进行标记和编码。"
      ],
      "metadata": {
        "id": "VJjQh1R5Trbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 构建分词器"
      ],
      "metadata": {
        "id": "fWBCDkziUFnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"google/mt5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "BS0G41fsT1GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 测试 mT5 分词器\n",
        "\n",
        "inputs = tokenizer(\"I loved reading the Hunger Games!\")\n",
        "inputs"
      ],
      "metadata": {
        "id": "6W-GcxD1UA_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(inputs.input_ids)"
      ],
      "metadata": {
        "id": "ZYr6tVxUUP_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "特殊的 Unicode 字符 ▁ 和序列结束标记 </s> 表明我们正在处理 SentencePiece 标记器，它基于第 6 章中讨论的 Unigram 分段算法。对于多语言语料库特别有用，因为它允许 SentencePiece 不受重音、标点符号以及许多语言（如日语）没有空白字符这一事实的影响。"
      ],
      "metadata": {
        "id": "cGqZkPHCUXia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = 512\n",
        "max_target_length = 30\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    model_inputs = tokenizer(\n",
        "        examples[\"review_body\"],\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "    )\n",
        "    labels = tokenizer(\n",
        "        examples[\"review_title\"], max_length=max_target_length, truncation=True\n",
        "    )\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "uNdM52xcUjfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = books_dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "ClMWutSCUyBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 文本摘要指标\n",
        "\n",
        "最常用的指标之一是 ROUGE 分数（面向回忆的基础评估的缩写）。该指标背后的基本思想是将生成的摘要与通常由人类创建的一组参考摘要进行比较。"
      ],
      "metadata": {
        "id": "XCqj5kTxU_Vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generated_summary = \"I absolutely loved reading the Hunger Games\"\n",
        "reference_summary = \"I loved reading the Hunger Games\""
      ],
      "metadata": {
        "id": "XMc8iaWgVUpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 加载 ROUGE 指标"
      ],
      "metadata": {
        "id": "hZxvV39sWFe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "t4deG4iCWJV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "rouge_score = evaluate.load(\"rouge\")"
      ],
      "metadata": {
        "id": "IbOzpmorWLXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 用 rouge_score.compute() 函数一次性计算所有指标\n",
        "scores = rouge_score.compute(\n",
        "    predictions=[generated_summary], references=[reference_summary]\n",
        ")\n",
        "scores"
      ],
      "metadata": {
        "id": "89QSV-aPWSCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " rouge1 变体是一元组的重叠——这只是表示单词重叠的一种奇特方式，并且正是我们上面讨论的度量标准。\n",
        "  rouge2 测量二元组之间的重叠（认为单词对的重叠），而 rougeL 和 rougeLsum 通过查找最长的单词匹配序列来测量单词的最长匹配序列生成的摘要和参考摘要中的公共子字符串。 rougeLsum 中的“总和”指的是该指标是在整个摘要上计算的，而 rougeL 是根据单个句子的平均值计算的。"
      ],
      "metadata": {
        "id": "-wOS2w1yWzrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores[\"rouge1\"].mid"
      ],
      "metadata": {
        "id": "oAztWt0YWpCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 建立强有力的基线"
      ],
      "metadata": {
        "id": "5nRhQASKXGFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "文本摘要的常见基线是简单地采用文章的前三个句子，通常称为 Lead-3 基线。我们可以使用句号来跟踪句子边界，但这对于像“U.S.”或“U.N.”这样的首字母缩略词来说会失败。- 因此我们将使用 nltk 库，其中包含更好的算法来处理这些情况。"
      ],
      "metadata": {
        "id": "-0fgDdtEXR6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "ov1SxlkgXiqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "id": "W3V6JGSDXlMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "接下来，我们从 nltk 导入句子标记器并创建一个简单的函数来提取评论中的前三个句子。文本摘要中的约定是用换行符分隔每个摘要，因此我们也将其包括在内并在训练示例中进行测试："
      ],
      "metadata": {
        "id": "UDgn2U7TXva_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "\n",
        "def three_sentence_summary(text):\n",
        "    return \"\\n\".join(sent_tokenize(text)[:3])\n",
        "\n",
        "\n",
        "print(three_sentence_summary(books_dataset[\"train\"][1][\"review_body\"]))"
      ],
      "metadata": {
        "id": "Ob8BKbeVXrX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_baseline(dataset, metric):\n",
        "    summaries = [three_sentence_summary(text) for text in dataset[\"review_body\"]]\n",
        "    return metric.compute(predictions=summaries, references=dataset[\"review_title\"])"
      ],
      "metadata": {
        "id": "IQ0EUTspYAKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用evaluate_baseline来计算验证集上的 ROUGE 分数\n",
        "import pandas as pd\n",
        "\n",
        "score = evaluate_baseline(books_dataset[\"validation\"], rouge_score)\n",
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "rouge_dict = dict((rn, round(score[rn].mid.fmeasure * 100, 2)) for rn in rouge_names)\n",
        "rouge_dict"
      ],
      "metadata": {
        "id": "qO2eGxpOYFme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 使用 Trainer API 微调 mT5"
      ],
      "metadata": {
        "id": "k3qLKqWuYVRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 加载模型"
      ],
      "metadata": {
        "id": "aapR1IrGYb8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "ilxo8vZQYbJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 定义训练参数"
      ],
      "metadata": {
        "id": "0zKqmbe_Yqs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "batch_size = 8\n",
        "num_train_epochs = 8\n",
        "# Show the training loss with every epoch\n",
        "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=f\"{model_name}-finetuned-amazon-en-es\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5.6e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    predict_with_generate=True,\n",
        "    logging_steps=logging_steps,\n",
        "    push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "Dt5Q5gt8YmRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 为训练器提供 compute_metrics() 函数"
      ],
      "metadata": {
        "id": "EndP6MLKZDRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    # Decode generated summaries into text\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    # Decode reference summaries into text\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    # ROUGE expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    # Compute ROUGE scores\n",
        "    result = rouge_score.compute(\n",
        "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "    )\n",
        "    # Extract the median scores\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ],
      "metadata": {
        "id": "98evnxKxY-S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 定义数据整理器"
      ],
      "metadata": {
        "id": "dhMPX0QjZJ42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "X-F4b-yrZL47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = tokenized_datasets.remove_columns(\n",
        "    books_dataset[\"train\"].column_names\n",
        ")\n",
        "\n",
        "features = [tokenized_datasets[\"train\"][i] for i in range(2)]\n",
        "data_collator(features)"
      ],
      "metadata": {
        "id": "p7PmD5VLZVem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 训练模型"
      ],
      "metadata": {
        "id": "pLFiNz52ZqI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "ixO0E-PZZgDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(commit_message=\"Training complete\", tags=\"summarization\")"
      ],
      "metadata": {
        "id": "zwexSSE5Ztq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 使用 🤗 Accelerate 微调 mT5"
      ],
      "metadata": {
        "id": "FbRVgWrlZ3f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 准备好训练的一切"
      ],
      "metadata": {
        "id": "uIjntarXaSNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 在数据集中将格式设置为 \"torch\"：由于 PyTorch 数据加载器需要批量张量\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "# 再次实例化 DataCollatorForSeq2Seq\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "PUj4sR2faR0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 实例化数据整理器并使用它来定义我们的数据加载器\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 8\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"],\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "SFqqmlR6Z0NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "# 优化器\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "fk6iUggtbIJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator\n",
        "# 将模型、优化器和数据加载器提供给 accelerator.prepare() 方法\n",
        "accelerator = Accelerator()\n",
        "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
        "    model, optimizer, train_dataloader, eval_dataloader\n",
        ")"
      ],
      "metadata": {
        "id": "OviMa9uFbM2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "num_train_epochs = 10\n",
        "num_update_steps_per_epoch = len(train_dataloader)\n",
        "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")"
      ],
      "metadata": {
        "id": "vZdhk_XLbU6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 后处理\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    # ROUGE expects a newline after each sentence\n",
        "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "\n",
        "    return preds, labels"
      ],
      "metadata": {
        "id": "qeAIvs0pbYtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import get_full_repo_name\n",
        "\n",
        "model_name = \"test-bert-finetuned-squad-accelerate\"\n",
        "repo_name = get_full_repo_name(model_name)\n",
        "repo_name"
      ],
      "metadata": {
        "id": "LJ-e5VQabcWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import Repository\n",
        "\n",
        "output_dir = \"results-mt5-finetuned-squad-accelerate\"\n",
        "repo = Repository(output_dir, clone_from=repo_name)"
      ],
      "metadata": {
        "id": "LZX55vm1belY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 循环训练"
      ],
      "metadata": {
        "id": "_h2rl14JbrDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "文本摘要的训练循环与我们遇到的其他 🤗 Accelerate 示例非常相似，大致分为四个主要步骤：\n",
        "\n",
        "- 通过迭代每个时期的 train_dataloader 中的所有示例来训练模型。\n",
        "- 在每个时期结束时生成模型摘要，首先生成标记，然后将它们（和参考摘要）解码为文本。\n",
        "- 使用我们之前看到的相同技术计算 ROUGE 分数。\n",
        "- 保存检查点并将所有内容推送到集线器。"
      ],
      "metadata": {
        "id": "4_CFGYj8b0s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "for epoch in range(num_train_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        accelerator.backward(loss)\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    for step, batch in enumerate(eval_dataloader):\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = accelerator.unwrap_model(model).generate(\n",
        "                batch[\"input_ids\"],\n",
        "                attention_mask=batch[\"attention_mask\"],\n",
        "            )\n",
        "\n",
        "            generated_tokens = accelerator.pad_across_processes(\n",
        "                generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
        "            )\n",
        "            labels = batch[\"labels\"]\n",
        "\n",
        "            # If we did not pad to max length, we need to pad the labels too\n",
        "            labels = accelerator.pad_across_processes(\n",
        "                batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id\n",
        "            )\n",
        "\n",
        "            generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()\n",
        "            labels = accelerator.gather(labels).cpu().numpy()\n",
        "\n",
        "            # Replace -100 in the labels as we can't decode them\n",
        "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "            if isinstance(generated_tokens, tuple):\n",
        "                generated_tokens = generated_tokens[0]\n",
        "            decoded_preds = tokenizer.batch_decode(\n",
        "                generated_tokens, skip_special_tokens=True\n",
        "            )\n",
        "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "            decoded_preds, decoded_labels = postprocess_text(\n",
        "                decoded_preds, decoded_labels\n",
        "            )\n",
        "\n",
        "            rouge_score.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "    # Compute metrics\n",
        "    result = rouge_score.compute()\n",
        "    # Extract the median ROUGE scores\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    print(f\"Epoch {epoch}:\", result)\n",
        "\n",
        "    # Save and upload\n",
        "    accelerator.wait_for_everyone()\n",
        "    unwrapped_model = accelerator.unwrap_model(model)\n",
        "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
        "    if accelerator.is_main_process:\n",
        "        tokenizer.save_pretrained(output_dir)\n",
        "        repo.push_to_hub(\n",
        "            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
        "        )"
      ],
      "metadata": {
        "id": "8fWrrdsibw8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 使用您的微调模型"
      ],
      "metadata": {
        "id": "lXiNul7lcL0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "hub_model_id = \"huggingface-course/mt5-small-finetuned-amazon-en-es\"\n",
        "summarizer = pipeline(\"summarization\", model=hub_model_id)\n",
        "\n",
        "def print_summary(idx):\n",
        "    review = books_dataset[\"test\"][idx][\"review_body\"]\n",
        "    title = books_dataset[\"test\"][idx][\"review_title\"]\n",
        "    summary = summarizer(books_dataset[\"test\"][idx][\"review_body\"])[0][\"summary_text\"]\n",
        "    print(f\"'>>> Review: {review}'\")\n",
        "    print(f\"\\n'>>> Title: {title}'\")\n",
        "    print(f\"\\n'>>> Summary: {summary}'\")"
      ],
      "metadata": {
        "id": "T7etsIK4cWsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_summary(100)"
      ],
      "metadata": {
        "id": "7Bt17IO9chZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_summary(0)"
      ],
      "metadata": {
        "id": "HBzcxVPyckMm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}