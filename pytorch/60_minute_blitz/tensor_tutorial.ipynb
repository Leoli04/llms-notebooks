{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Leoli04/llms-notebooks/blob/main/pytorch/tensor_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OixNcYJlXjE"
   },
   "source": [
    "Tensors\n",
    "=======\n",
    "\n",
    "张量是一种特殊的数据结构，与数组和矩阵非常相似。在 PyTorch 中，我们使用张量对模型的输入和输出以及模型的参数进行编码。\n",
    "\n",
    "张量与 NumPy 的 ndarray 类似，不同之处在于张量可以在 GPU 或其他专用硬件上运行以加速计算。如果您熟悉 ndarrays，那么您就会熟悉 Tensor API。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8PNY5S6lXjG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HP1snlAclXjH"
   },
   "source": [
    "Tensor 初始化\n",
    "=====================\n",
    "\n",
    "张量可以通过多种方式初始化。看看下面的例子：\n",
    "\n",
    "**直接来自数据**\n",
    "\n",
    "张量可以直接从数据创建。数据类型是自动推断的。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUL3UTMHlXjI",
    "outputId": "43aedf65-c3fd-4aa3-d7c4-7aea42bc69bd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7kBC7FplXjI"
   },
   "source": [
    "**来自 NumPy 数组**\n",
    "\n",
    "张量可以从 NumPy 数组创建.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZdakO-7lXjJ",
    "outputId": "ae3a81b1-049c-4751-da7b-ec2564b50532",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZh_OeYylXjJ"
   },
   "source": [
    "**从另一个张量:**\n",
    "\n",
    "新张量保留参数张量的属性（形状、数据类型），除非显式覆盖。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Slk_4S1XlXjJ",
    "outputId": "922a6bda-e42a-4c58-a7c9-5dd1a3a5a729",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.4843, 0.4520],\n",
      "        [0.0332, 0.4764]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0PVblSnlXjK"
   },
   "source": [
    "**使用随机值或常数值:**\n",
    "\n",
    "`shape` 是张量维度的元组。在下面的函数中，它确定输出张量的维数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1dlB9cNlXjL",
    "outputId": "feaaac60-1a7e-4c58-dd8f-e8efac98082c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.7612, 0.5418, 0.0320],\n",
      "        [0.8448, 0.9504, 0.7341]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dkumHpXlXjL"
   },
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUu5xO_3lXjL"
   },
   "source": [
    "Tensor 属性\n",
    "=================\n",
    "\n",
    "张量属性描述了它们的形状、数据类型以及存储它们的设备。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBpsCVgRlXjM",
    "outputId": "17215f81-b108-4ba6-966a-a6654f93eefd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPH3JD5ulXjM"
   },
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdFNnpaBlXjM"
   },
   "source": [
    "Tensor 操作\n",
    "=================\n",
    "\n",
    "tensor操作包括转置、索引、切片、数学运算、线性代数、随机采样等。具体看[here](https://pytorch.org/docs/stable/torch.html)\n",
    "\n",
    "\n",
    "\n",
    "它们中的每一个都可以在 GPU 上运行（速度通常高于 CPU）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iumMZkL0lXjM",
    "outputId": "c25f77de-d4e0-4351-a74f-b580218354da",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "  tensor = tensor.to('cuda')\n",
    "  print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryf9JoKilXjN"
   },
   "source": [
    "**类似 numpy 的索引和切片:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_L6Qf8-VlXjN",
    "outputId": "18b2e09e-7fc8-4ef9-e621-cdef5b9189ee",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_Dz8msdlXjN"
   },
   "source": [
    "**Joining tensors** 您可以使用 torch.cat 沿给定维度连接一系列张量.另请参见 torch.stack，另一个张量连接操作，与 torch.cat 略有不同。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xFbIgeTlXjO",
    "outputId": "d5650382-c0e2-4d59-a83d-1107e6ba0f89",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RkRKTfQlXjO"
   },
   "source": [
    "**tensors相乘**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8zSSrU5WlXjO",
    "outputId": "ee538264-dde8-4a47-d8bf-26baf06e43e6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor.mul(tensor) \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor * tensor \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# This computes the element-wise product\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor * tensor \\n {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb8aadP6lXjO"
   },
   "source": [
    "This computes the matrix multiplication between two tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwhEAOl9lXjO",
    "outputId": "2286509d-06ae-4da4-8482-a274037e9d35",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor.matmul(tensor.T) \n",
      " tensor([[4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.]]) \n",
      "\n",
      "tensor @ tensor.T \n",
      " tensor([[4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# tensor.T 是 tensor 的转置，即将其行列互换。\n",
    "tensor = torch.ones(4, 4)\n",
    "print(tensor.T)\n",
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQkZZwnClXjP"
   },
   "source": [
    "**In-place operations** 具有 _ 后缀的操作是就地操作。例如： x.copy_(y) 、 x.t_() 会更改 x 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkjm68u9lXjP",
    "outputId": "20404958-73a4-4d7f-ba2f-5ebc05e7e41d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mv4GvtQ4lXjP"
   },
   "source": [
    "<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n",
    "<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n",
    "<p>In-place operations 可以节省一些内存，但在计算导数时可能会出现问题，因为历史记录会立即丢失。因此，不鼓励使用它们。.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdCnzQaZlXjP"
   },
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WV4YKcUilXjP"
   },
   "source": [
    " 与 NumPy 之间的转换\n",
    "=================\n",
    "\n",
    "  CPU上的Tensors 和 NumPy 数组可以共享它们的底层内存位置，改变一个就会改变另一个。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Edc7risnlXjP"
   },
   "source": [
    "Tensor to NumPy array\n",
    "=====================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZlGUbNvnlXjQ",
    "outputId": "15099c0e-b4ac-40ac-a34d-a27bd4ab9f37",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_CtKhrKlXjQ"
   },
   "source": [
    "张量的变化反映在 NumPy 数组中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VySyw9g2lXjQ",
    "outputId": "d37fb1ea-e419-4c96-802a-32bf969e150c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85DmTQSOlXjQ"
   },
   "source": [
    "NumPy array to Tensor\n",
    "=====================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdWVmQoNlXjQ"
   },
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4R2PkcKmlXjR"
   },
   "source": [
    "NumPy 数组中的变化反映在张量中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsxD8zgRlXjR",
    "outputId": "029ba208-d260-441d-e6cc-dcd6c62a83f6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "CUDA 张量\n",
    "=====================\n",
    "\n",
    "Tensors 可以通过 .to 方法转换到不同的设备上，即 CPU 或者 GPU 上。例子如下所示："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 当 CUDA 可用的时候，可用运行下方这段代码，采用 torch.device() 方法来改变 tensors 是否在 GPU 上进行计算操作\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # 定义一个 CUDA 设备对象\n",
    "    y = torch.ones_like(x, device=device)  # 显示创建在 GPU 上的一个 tensor\n",
    "    x = x.to(device)                       # 也可以采用 .to(\"cuda\")\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # .to() 方法也可以改变数值类型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "输出结果，第一个结果就是在 GPU 上的结果，打印变量的时候会带有 device='cuda:0'，而第二个是在 CPU 上的变量。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tensor([1.4549], device='cuda:0')\n",
    "tensor([1.4549], dtype=torch.float64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}